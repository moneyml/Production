{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from nlp_utils import clean_text, pos_tag_text\n",
    "sys.path.append(\"../\")\n",
    "from param_config import config\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "import datetime\n",
    "\n",
    "pd.set_option('display.float_format',lambda x: '%.5f'%x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfAll = pd.read_csv('../../Data/All_Data_dedup_zero.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220X25\n",
      "220X34\n",
      "220X35\n",
      "220X36\n",
      "220X37\n",
      "220X38\n",
      "220X39\n",
      "220X40\n",
      "220X222\n",
      "300X15\n",
      "300X16\n",
      "300X17\n",
      "300X18\n",
      "300X19\n",
      "311X2\n",
      "311X6\n",
      "311X14\n",
      "311X24\n",
      "312X5\n",
      "312X10\n",
      "312X15\n",
      "312X20\n",
      "312X25\n",
      "312X30\n",
      "312X35\n",
      "312X40\n",
      "312X45\n",
      "312X50\n",
      "312X103\n",
      "312X109\n",
      "312X151\n",
      "312X157\n",
      "312X205\n",
      "312X275\n",
      "312X299\n",
      "312X305\n",
      "312X317\n",
      "312X323\n",
      "312X329\n",
      "312X347\n",
      "312X371\n",
      "312X395\n",
      "312X401\n",
      "312X407\n",
      "312X413\n",
      "312X419\n",
      "312X454\n",
      "312X460\n",
      "312X466\n",
      "312X472\n",
      "312X496\n",
      "312X502\n",
      "312X508\n",
      "312X514\n",
      "312X538\n",
      "312X544\n",
      "312X550\n",
      "312X556\n",
      "312X562\n",
      "312X568\n",
      "312X610\n",
      "312X616\n",
      "312X622\n",
      "312X628\n",
      "312X652\n",
      "312X658\n",
      "312X664\n",
      "312X688\n",
      "312X709\n",
      "312X750\n",
      "312X756\n",
      "312X798\n",
      "420X17\n",
      "420X24\n",
      "420X29\n",
      "420X39\n",
      "420X46\n",
      "420X47\n",
      "420X107\n",
      "420X109\n",
      "420X111\n",
      "420X113\n",
      "420X119\n",
      "420X125\n",
      "420X133\n",
      "420X137\n",
      "420X143\n",
      "420X155\n",
      "420X158\n",
      "420X161\n",
      "420X186\n",
      "420X203\n",
      "420X204\n",
      "420X206\n",
      "420X207\n",
      "420X226\n",
      "420X227\n",
      "420X229\n",
      "420X230\n",
      "520X2\n",
      "520X4\n",
      "520X9\n",
      "520X10\n",
      "520X20\n",
      "520X54\n",
      "520X139\n",
      "520X163\n",
      "520X170\n",
      "520X172\n",
      "520X175\n",
      "520X185\n",
      "520X193\n",
      "520X194\n",
      "520X221\n",
      "520X280\n",
      "520X286\n",
      "520X292\n",
      "520X298\n",
      "520X299\n",
      "520X300\n",
      "520X301\n",
      "520X302\n",
      "520X303\n",
      "520X304\n",
      "520X310\n",
      "520X316\n",
      "520X328\n",
      "520X334\n",
      "520X384\n",
      "520X398\n",
      "520X401\n",
      "520X402\n",
      "520X429\n",
      "520X431\n",
      "520X433\n",
      "520X434\n",
      "750X5\n",
      "750X8\n",
      "750X13\n",
      "750X14\n",
      "750X15\n",
      "750X16\n",
      "750X17\n",
      "750X18\n",
      "750X19\n",
      "750X20\n",
      "750X21\n",
      "750X35\n",
      "750X36\n",
      "750X37\n",
      "750X38\n",
      "750X39\n",
      "750X40\n",
      "750X41\n",
      "750X42\n",
      "750X43\n",
      "750X93\n",
      "750X96\n",
      "750X110\n",
      "750X112\n",
      "750X692\n",
      "750X693\n",
      "750X695\n",
      "750X696\n",
      "750X698\n",
      "750X700\n",
      "750X714\n",
      "750X715\n",
      "750X716\n",
      "750X717\n",
      "750X718\n",
      "750X719\n",
      "750X729\n",
      "750X730\n",
      "750X740\n",
      "750X752\n",
      "750X762\n",
      "750X796\n",
      "750X806\n",
      "750X807\n",
      "750X817\n",
      "750X829\n",
      "750X839\n",
      "750X840\n",
      "750X850\n",
      "750X862\n",
      "750X871\n",
      "750X916\n",
      "750X926\n",
      "750X949\n",
      "750X959\n",
      "750X961\n",
      "750X962\n",
      "750X963\n",
      "750X965\n",
      "750X966\n",
      "750X968\n",
      "750X969\n",
      "750X972\n",
      "750X982\n",
      "750X1153\n",
      "750X1154\n",
      "750X1155\n",
      "750X1157\n",
      "750X1158\n",
      "750X1160\n",
      "750X1161\n",
      "750X1163\n",
      "750X1214\n",
      "750X1217\n",
      "750X1222\n",
      "750X1223\n",
      "750X1224\n",
      "750X1226\n",
      "750X1227\n",
      "750X1229\n",
      "750X1230\n",
      "750X1347\n",
      "750X1350\n",
      "750X1370\n",
      "750X1380\n",
      "750X1398\n",
      "750X1408\n",
      "750X1442\n",
      "750X1452\n"
     ]
    }
   ],
   "source": [
    "for var in dfAll.columns:\n",
    "    if dfAll[var].dtypes!='object':\n",
    "        if dfAll[var].nunique()==1:\n",
    "            print(var)\n",
    "            del dfAll[var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 3217)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_list = dfAll.columns.tolist()[14:]\n",
    "dfAll_tmp = dfAll.loc[dfAll['ID']!='ID454']\n",
    "dfTmp = dfAll_tmp[feat_list]\n",
    "dfTmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zero_cnt = (dfTmp==0).sum().to_dict()\n",
    "zero_cnt2 = {}\n",
    "for key, value in zero_cnt.items():\n",
    "    if not zero_cnt2.__contains__(value) and value!=0:\n",
    "        zero_cnt2[value] =[key]\n",
    "    elif value!=0:\n",
    "        zero_cnt2[value].append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 ['210X1', '210X2', '210X3', '210X4', '210X5', '210X6', '210X11', '210X12', '210X39', '210X52', '210X209', '210X210']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 ['210X13', '210X14', '210X15', '210X16', '210X25', '210X26', '210X27', '210X28', '210X32', '210X33', '210X34', '210X35', '210X40', '210X41', '210X42', '210X43', '210X44', '210X45', '210X46', '210X47', '210X48', '210X49', '210X50', '210X51', '210X53', '210X54', '210X55', '210X56', '210X57', '210X58', '210X59', '210X60', '210X61', '210X62', '210X63', '210X64', '210X65', '210X66', '210X67', '210X68', '210X69', '210X70', '210X71', '210X72', '210X73', '210X74', '210X75', '210X76', '210X81', '210X82', '210X83', '210X84', '210X85', '210X86', '210X87', '210X88', '210X112', '210X113', '210X114', '210X115', '210X116', '210X117', '210X118', '210X119', '210X120', '210X121', '210X122', '210X123', '210X124', '210X125', '210X126', '210X127', '210X128', '210X129', '210X130', '210X131', '210X132', '210X133', '210X134', '210X135', '210X136', '210X137', '210X138', '210X139', '210X140', '210X141', '210X142', '210X143', '210X144', '210X145', '210X146', '210X147', '210X148', '210X149', '210X150', '210X151', '210X153', '210X154', '210X155', '210X156', '210X157', '210X158', '210X159', '210X160', '210X161', '210X162', '210X163', '210X164', '210X165', '210X166', '210X167', '210X168', '210X169', '210X170', '210X171', '210X172', '210X173', '210X174', '210X175', '210X176', '210X177', '210X178', '210X179', '210X182', '210X200', '210X201', '210X202', '210X203', '210X211', '210X212']\n",
      "72 ['210X228', '210X229', '210X230', '210X231']\n",
      "371 ['220X289', '220X485']\n",
      "508 ['220X526', '220X554']\n",
      "711 ['220X551', '220X557']\n",
      "257 ['311X66', '311X154', '261X340', '261X526', '261X712']\n",
      "162 ['311X69', '311X157', '261X343', '261X529', '261X715']\n",
      "36 ['312X70', '312X71', '312X72', '312X76', '312X77', '312X78', '312X81', '312X82', '312X83', '312X84', '400X141']\n",
      "76 ['330X35', '330X38', '330X101', '330X103', '330X627', '330X629', '330X631', '330X634', '330X749']\n",
      "6 ['344X237', '344X285']\n",
      "714 ['344X270', '344X306']\n"
     ]
    }
   ],
   "source": [
    "dfTmp2 = dfTmp.copy(deep=True)\n",
    "for key, value in zero_cnt2.items():\n",
    "    if len(value)<2:\n",
    "        continue\n",
    "    check = 1\n",
    "    ind = dfTmp2.loc[dfTmp2[value[0]]==0].index.tolist()\n",
    "    for var in value[1:]:\n",
    "        if var=='400X141':\n",
    "            continue\n",
    "        if ind!=dfTmp2.loc[dfTmp2[var]==0].index.tolist():\n",
    "            check=0\n",
    "            break\n",
    "    if check==1:\n",
    "        print(key,value)\n",
    "        dfTmp.loc[dfTmp[value[0]]==0,value]=np.nan\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfAll.loc[dfAll['ID']!='ID454',feat_list] = dfTmp[feat_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303    True\n",
       "Name: 210X1, dtype: bool"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAll.loc[dfAll['ID']=='ID454',var]==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210X1\n",
      "210X2\n",
      "210X3\n",
      "210X4\n",
      "210X5\n",
      "210X6\n",
      "210X10\n",
      "210X11\n",
      "210X12\n",
      "210X13\n",
      "210X14\n",
      "210X15\n",
      "210X16\n",
      "210X19\n",
      "210X20\n",
      "210X21\n",
      "210X23\n",
      "210X25\n",
      "210X26\n",
      "210X27\n",
      "210X28\n",
      "210X32\n",
      "210X33\n",
      "210X34\n",
      "210X35\n",
      "210X36\n",
      "210X39\n",
      "210X40\n",
      "210X41\n",
      "210X42\n",
      "210X43\n",
      "210X44\n",
      "210X45\n",
      "210X46\n",
      "210X47\n",
      "210X48\n",
      "210X49\n",
      "210X50\n",
      "210X51\n",
      "210X52\n",
      "210X53\n",
      "210X54\n",
      "210X55\n",
      "210X56\n",
      "210X57\n",
      "210X58\n",
      "210X59\n",
      "210X60\n",
      "210X61\n",
      "210X62\n",
      "210X63\n",
      "210X64\n",
      "210X65\n",
      "210X66\n",
      "210X67\n",
      "210X68\n",
      "210X69\n",
      "210X70\n",
      "210X71\n",
      "210X72\n",
      "210X73\n",
      "210X74\n",
      "210X75\n",
      "210X76\n",
      "210X77\n",
      "210X81\n",
      "210X82\n",
      "210X83\n",
      "210X84\n",
      "210X85\n",
      "210X86\n",
      "210X87\n",
      "210X88\n",
      "210X89\n",
      "210X90\n",
      "210X91\n",
      "210X92\n",
      "210X93\n",
      "210X94\n",
      "210X95\n",
      "210X96\n",
      "210X100\n",
      "210X101\n",
      "210X102\n",
      "210X104\n",
      "210X105\n",
      "210X106\n",
      "210X107\n",
      "210X108\n",
      "210X110\n",
      "210X112\n",
      "210X113\n",
      "210X114\n",
      "210X115\n",
      "210X116\n",
      "210X117\n",
      "210X118\n",
      "210X119\n",
      "210X120\n",
      "210X121\n",
      "210X122\n",
      "210X123\n",
      "210X124\n",
      "210X125\n",
      "210X126\n",
      "210X127\n",
      "210X128\n",
      "210X129\n",
      "210X130\n",
      "210X131\n",
      "210X132\n",
      "210X133\n",
      "210X134\n",
      "210X135\n",
      "210X136\n",
      "210X137\n",
      "210X138\n",
      "210X139\n",
      "210X140\n",
      "210X141\n",
      "210X142\n",
      "210X143\n",
      "210X144\n",
      "210X145\n",
      "210X146\n",
      "210X147\n",
      "210X148\n",
      "210X149\n",
      "210X150\n",
      "210X151\n",
      "210X153\n",
      "210X154\n",
      "210X155\n",
      "210X156\n",
      "210X157\n",
      "210X158\n",
      "210X159\n",
      "210X160\n",
      "210X161\n",
      "210X162\n",
      "210X163\n",
      "210X164\n",
      "210X165\n",
      "210X166\n",
      "210X167\n",
      "210X168\n",
      "210X169\n",
      "210X170\n",
      "210X171\n",
      "210X172\n",
      "210X173\n",
      "210X174\n",
      "210X175\n",
      "210X176\n",
      "210X177\n",
      "210X178\n",
      "210X179\n",
      "210X182\n",
      "210X184\n",
      "210X185\n",
      "210X186\n",
      "210X187\n",
      "210X188\n",
      "210X189\n",
      "210X190\n",
      "210X192\n",
      "210X194\n",
      "210X195\n",
      "210X199\n",
      "210X200\n",
      "210X201\n",
      "210X202\n",
      "210X203\n",
      "210X206\n",
      "210X207\n",
      "210X209\n",
      "210X210\n",
      "210X211\n",
      "210X212\n",
      "210X214\n",
      "210X216\n",
      "210X217\n",
      "210X218\n",
      "210X219\n",
      "210X220\n",
      "210X222\n",
      "210X225\n",
      "210X226\n",
      "210X228\n",
      "210X229\n",
      "210X230\n",
      "210X231\n",
      "220X526\n",
      "220X551\n",
      "220X554\n",
      "220X557\n",
      "330X35\n",
      "330X38\n",
      "330X101\n",
      "330X103\n",
      "330X627\n",
      "330X629\n",
      "330X631\n",
      "330X634\n",
      "330X749\n",
      "344X270\n",
      "344X306\n"
     ]
    }
   ],
   "source": [
    "for var in feat_list:\n",
    "    if ((dfAll[var]==0).sum())==1 and dfAll.loc[dfAll['ID']=='ID454',var].values[0]==0:\n",
    "        print(var)\n",
    "        dfAll.loc[dfAll['ID']=='ID454',var]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfAll.to_csv('../../Data/All_Data_dedup_zero.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 ['210X228', '210X229', '210X230', '210X231']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371 ['220X289', '220X485']\n",
      "208 ['220X300', '220X348', '220X496']\n",
      "509 ['220X526', '220X554']\n",
      "712 ['220X551', '220X557']\n",
      "424 ['310X19', '310X20', '310X21', '310X22', '310X23', '310X24']\n",
      "257 ['311X66', '311X154', '261X340', '261X526', '261X712']\n",
      "162 ['311X69', '311X157', '261X343', '261X529', '261X715']\n",
      "77 ['330X35', '330X38', '330X101', '330X103', '330X627', '330X629', '330X631', '330X634', '330X749']\n",
      "6 ['344X237', '344X285']\n",
      "715 ['344X270', '344X306']\n"
     ]
    }
   ],
   "source": [
    "dfTmp2 = dfTmp.copy(deep=True)\n",
    "for key, value in zero_cnt2.items():\n",
    "    if len(value)<2:\n",
    "        continue\n",
    "    check = 1\n",
    "    ind = dfTmp2.loc[dfTmp2[value[0]]==0].index.tolist()\n",
    "    for var in value[1:]:\n",
    "        if ind!=dfTmp2.loc[dfTmp2[var]==0].index.tolist():\n",
    "            check=0\n",
    "            break\n",
    "    if check==1:\n",
    "        print(key,value)\n",
    "        dfTmp.loc[dfTmp[value[0]]==0,value]=np.nan\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfAll2 = pd.read_csv('../../Data/All_Data_dedup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(721, 3231)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for var in dfAll.columns:\n",
    "    if 'TOOL' in var:\n",
    "        del dfAll[var]'''\n",
    "dfAll3 = dfAll.merge(dfAll2.iloc[:,0:14],'inner','ID')\n",
    "dfAll3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for var in dfAll.columns:\n",
    "    if 'TOOL' in var:\n",
    "        tmpTrain = pd.get_dummies(dfAll[var],prefix=var,dummy_na=True)\n",
    "        dfAll = pd.concat([dfAll,tmpTrain],axis=1)\n",
    "        del dfAll[var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = dfAll.isnull().sum().to_dict()\n",
    "null_dict ={}\n",
    "for key,value in tmp.items():\n",
    "    if key=='ID':\n",
    "        continue\n",
    "    if not null_dict.__contains__(value):\n",
    "        null_dict[value] = [key]\n",
    "    else:\n",
    "        null_dict[value].append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 12,\n",
       " 19,\n",
       " 21,\n",
       " 29,\n",
       " 30,\n",
       " 35,\n",
       " 36,\n",
       " 41,\n",
       " 71,\n",
       " 73,\n",
       " 77,\n",
       " 162,\n",
       " 257,\n",
       " 348,\n",
       " 366,\n",
       " 375,\n",
       " 513,\n",
       " 715,\n",
       " 716]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = list(null_dict.keys())\n",
    "keys.sort()\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for key,value in null_dict.items():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210X10\n",
      "210X19\n",
      "210X20\n",
      "210X21\n",
      "210X23\n",
      "210X36\n",
      "210X77\n",
      "210X89\n",
      "210X90\n",
      "210X91\n",
      "210X92\n",
      "210X93\n",
      "210X94\n",
      "210X95\n",
      "210X96\n",
      "210X100\n",
      "210X101\n",
      "210X102\n",
      "210X104\n",
      "210X105\n",
      "210X106\n",
      "210X107\n",
      "210X108\n",
      "210X110\n",
      "210X184\n",
      "210X185\n",
      "210X186\n",
      "210X187\n",
      "210X188\n",
      "210X189\n",
      "210X190\n",
      "210X192\n",
      "210X194\n",
      "210X195\n",
      "210X199\n",
      "210X206\n",
      "210X207\n",
      "210X214\n",
      "210X216\n",
      "210X217\n",
      "210X218\n",
      "210X219\n",
      "210X220\n",
      "210X222\n",
      "210X225\n",
      "210X226\n",
      "220X26\n",
      "220X27\n",
      "220X28\n",
      "220X29\n",
      "220X30\n",
      "220X31\n",
      "220X32\n",
      "220X33\n",
      "220X53\n",
      "220X54\n",
      "220X55\n",
      "220X67\n",
      "220X107\n",
      "220X108\n",
      "220X223\n",
      "220X224\n",
      "420X1\n",
      "420X4\n",
      "420X12\n",
      "420X13\n",
      "420X14\n",
      "420X15\n",
      "420X16\n",
      "420X19\n",
      "420X20\n",
      "420X21\n",
      "420X22\n",
      "420X23\n",
      "420X30\n",
      "420X31\n",
      "420X32\n",
      "420X33\n",
      "420X34\n",
      "420X35\n",
      "420X36\n",
      "420X37\n",
      "420X38\n",
      "420X40\n",
      "420X66\n",
      "420X67\n",
      "420X68\n",
      "420X69\n",
      "420X70\n",
      "420X71\n",
      "420X72\n",
      "420X73\n",
      "420X74\n",
      "420X75\n",
      "420X76\n",
      "420X77\n",
      "420X78\n",
      "420X79\n",
      "420X80\n",
      "420X81\n",
      "420X85\n",
      "420X86\n",
      "420X87\n",
      "420X88\n",
      "420X89\n",
      "420X90\n",
      "420X91\n",
      "420X92\n",
      "420X93\n",
      "420X94\n",
      "420X95\n",
      "420X96\n",
      "420X97\n",
      "420X98\n",
      "420X99\n",
      "420X100\n",
      "420X108\n",
      "420X110\n",
      "420X112\n",
      "420X114\n",
      "420X115\n",
      "420X116\n",
      "420X117\n",
      "420X118\n",
      "420X120\n",
      "420X121\n",
      "420X122\n",
      "420X123\n",
      "420X124\n",
      "420X132\n",
      "420X134\n",
      "420X135\n",
      "420X136\n",
      "420X138\n",
      "420X139\n",
      "420X140\n",
      "420X141\n",
      "420X142\n",
      "420X144\n",
      "420X145\n",
      "420X147\n",
      "420X148\n",
      "420X150\n",
      "420X151\n",
      "420X152\n",
      "420X153\n",
      "420X154\n",
      "420X156\n",
      "420X157\n",
      "420X159\n",
      "420X160\n",
      "420X187\n",
      "420X188\n",
      "420X189\n",
      "420X192\n",
      "420X193\n",
      "420X194\n",
      "420X195\n",
      "420X196\n",
      "420X197\n",
      "420X198\n",
      "420X199\n",
      "420X200\n",
      "420X201\n",
      "420X202\n",
      "420X205\n",
      "420X208\n",
      "420X209\n",
      "420X210\n",
      "420X211\n",
      "420X212\n",
      "420X213\n",
      "420X214\n",
      "420X215\n",
      "420X216\n",
      "420X217\n",
      "420X228\n",
      "220X225\n",
      "220X241\n",
      "220X247\n",
      "220X248\n",
      "220X249\n",
      "220X260\n",
      "220X262\n",
      "220X266\n",
      "220X269\n",
      "220X270\n",
      "220X271\n",
      "220X272\n",
      "220X273\n",
      "220X274\n",
      "220X275\n",
      "220X277\n",
      "220X279\n",
      "220X281\n",
      "220X282\n",
      "220X284\n",
      "220X286\n",
      "220X288\n",
      "220X290\n",
      "220X291\n",
      "220X293\n",
      "220X294\n",
      "220X295\n",
      "220X296\n",
      "220X297\n",
      "220X298\n",
      "220X299\n",
      "220X300\n",
      "220X301\n",
      "220X302\n",
      "220X303\n",
      "220X304\n",
      "220X305\n",
      "220X306\n",
      "220X307\n",
      "220X308\n",
      "220X309\n",
      "220X310\n",
      "220X311\n",
      "220X312\n",
      "220X313\n",
      "220X314\n",
      "220X315\n",
      "220X316\n",
      "220X317\n",
      "220X318\n",
      "220X321\n",
      "220X322\n",
      "220X323\n",
      "220X324\n",
      "220X325\n",
      "220X326\n",
      "220X327\n",
      "220X328\n",
      "220X329\n",
      "220X330\n",
      "220X331\n",
      "220X332\n",
      "220X333\n",
      "220X334\n",
      "220X335\n",
      "220X336\n",
      "220X337\n",
      "220X338\n",
      "220X339\n",
      "220X340\n",
      "220X341\n",
      "220X342\n",
      "220X343\n",
      "220X344\n",
      "220X345\n",
      "220X346\n",
      "220X347\n",
      "220X348\n",
      "220X349\n",
      "220X350\n",
      "220X351\n",
      "220X352\n",
      "220X353\n",
      "220X354\n",
      "220X355\n",
      "220X356\n",
      "220X357\n",
      "220X358\n",
      "220X359\n",
      "220X360\n",
      "220X361\n",
      "220X362\n",
      "220X363\n",
      "220X364\n",
      "220X365\n",
      "220X366\n",
      "220X367\n",
      "220X368\n",
      "220X369\n",
      "220X370\n",
      "220X371\n",
      "220X372\n",
      "220X373\n",
      "220X374\n",
      "220X375\n",
      "220X376\n",
      "220X377\n",
      "220X378\n",
      "220X379\n",
      "220X380\n",
      "220X381\n",
      "220X382\n",
      "220X383\n",
      "220X384\n",
      "220X385\n",
      "220X386\n",
      "220X387\n",
      "220X388\n",
      "220X389\n",
      "220X390\n",
      "220X392\n",
      "220X393\n",
      "220X394\n",
      "220X395\n",
      "220X397\n",
      "220X398\n",
      "220X399\n",
      "220X400\n",
      "220X402\n",
      "220X403\n",
      "220X404\n",
      "220X405\n",
      "220X406\n",
      "220X407\n",
      "220X408\n",
      "220X409\n",
      "220X410\n",
      "220X411\n",
      "220X412\n",
      "220X414\n",
      "220X415\n",
      "220X416\n",
      "220X417\n",
      "220X419\n",
      "220X420\n",
      "220X421\n",
      "220X422\n",
      "220X423\n",
      "220X424\n",
      "220X425\n",
      "220X428\n",
      "220X429\n",
      "220X431\n",
      "220X433\n",
      "220X434\n",
      "220X435\n",
      "220X437\n",
      "220X438\n",
      "220X439\n",
      "220X440\n",
      "220X441\n",
      "220X442\n",
      "220X443\n",
      "220X444\n",
      "220X445\n",
      "220X446\n",
      "220X447\n",
      "220X448\n",
      "220X449\n",
      "220X450\n",
      "220X451\n",
      "220X454\n",
      "220X457\n",
      "220X458\n",
      "220X459\n",
      "220X461\n",
      "220X462\n",
      "220X463\n",
      "220X465\n",
      "220X467\n",
      "220X468\n",
      "220X469\n",
      "220X470\n",
      "220X471\n",
      "220X472\n",
      "220X474\n",
      "220X475\n",
      "220X476\n",
      "220X477\n",
      "220X478\n",
      "220X479\n",
      "220X480\n",
      "220X481\n",
      "220X482\n",
      "220X483\n",
      "220X484\n",
      "220X486\n",
      "220X487\n",
      "220X488\n",
      "220X489\n",
      "220X490\n",
      "220X491\n",
      "220X492\n",
      "220X493\n",
      "220X494\n",
      "220X495\n",
      "220X496\n",
      "220X497\n",
      "220X498\n",
      "220X499\n",
      "220X500\n",
      "220X501\n",
      "220X502\n",
      "220X503\n",
      "220X504\n",
      "220X505\n",
      "220X506\n",
      "220X507\n",
      "220X508\n",
      "220X509\n",
      "220X510\n",
      "220X512\n",
      "220X514\n",
      "220X515\n",
      "220X516\n",
      "220X517\n",
      "220X518\n",
      "220X520\n",
      "220X521\n",
      "220X522\n",
      "220X523\n",
      "220X524\n",
      "220X528\n",
      "220X529\n",
      "220X530\n",
      "220X531\n",
      "220X533\n",
      "220X535\n",
      "220X539\n",
      "220X540\n",
      "220X541\n",
      "220X549\n",
      "220X550\n",
      "220X570\n",
      "220X571\n",
      "400X4\n",
      "400X12\n",
      "400X13\n",
      "400X14\n",
      "400X15\n",
      "400X16\n",
      "400X19\n",
      "400X20\n",
      "400X21\n",
      "400X22\n",
      "400X23\n",
      "400X30\n",
      "400X31\n",
      "400X32\n",
      "400X33\n",
      "400X34\n",
      "400X35\n",
      "400X36\n",
      "400X37\n",
      "400X38\n",
      "400X66\n",
      "400X67\n",
      "400X68\n",
      "400X69\n",
      "400X70\n",
      "400X71\n",
      "400X72\n",
      "400X73\n",
      "400X74\n",
      "400X75\n",
      "400X76\n",
      "400X77\n",
      "400X78\n",
      "400X79\n",
      "400X80\n",
      "400X81\n",
      "400X85\n",
      "400X86\n",
      "400X87\n",
      "400X88\n",
      "400X89\n",
      "400X90\n",
      "400X91\n",
      "400X92\n",
      "400X93\n",
      "400X94\n",
      "400X95\n",
      "400X96\n",
      "400X97\n",
      "400X98\n",
      "400X99\n",
      "400X100\n",
      "400X108\n",
      "400X109\n",
      "400X110\n",
      "400X111\n",
      "400X112\n",
      "400X114\n",
      "400X115\n",
      "400X116\n",
      "400X117\n",
      "400X118\n",
      "400X120\n",
      "400X121\n",
      "400X122\n",
      "400X123\n",
      "400X124\n",
      "400X132\n",
      "400X133\n",
      "400X134\n",
      "400X135\n",
      "400X136\n",
      "400X138\n",
      "400X139\n",
      "400X140\n",
      "400X142\n",
      "400X144\n",
      "400X145\n",
      "400X146\n",
      "400X147\n",
      "400X148\n",
      "400X151\n",
      "400X152\n",
      "400X153\n",
      "400X154\n",
      "400X156\n",
      "400X157\n",
      "400X158\n",
      "400X159\n",
      "400X160\n",
      "400X187\n",
      "400X188\n",
      "400X189\n",
      "400X192\n",
      "400X193\n",
      "400X194\n",
      "400X195\n",
      "400X196\n",
      "400X197\n",
      "400X198\n",
      "400X199\n",
      "400X200\n",
      "400X201\n",
      "400X202\n",
      "400X204\n",
      "400X205\n",
      "400X208\n",
      "400X209\n",
      "400X210\n",
      "400X211\n",
      "400X212\n",
      "400X213\n",
      "400X214\n",
      "400X215\n",
      "400X216\n",
      "400X217\n",
      "400X228\n",
      "344X237\n",
      "344X285\n",
      "520X174\n",
      "520X345\n",
      "520X140\n",
      "520X143\n",
      "520X158\n",
      "520X159\n",
      "520X160\n",
      "520X161\n",
      "520X162\n",
      "520X165\n",
      "520X166\n",
      "520X167\n",
      "520X168\n",
      "520X169\n",
      "520X176\n",
      "520X177\n",
      "520X178\n",
      "520X179\n",
      "520X180\n",
      "520X181\n",
      "520X182\n",
      "520X183\n",
      "520X184\n",
      "520X186\n",
      "520X230\n",
      "520X231\n",
      "520X232\n",
      "520X233\n",
      "520X234\n",
      "520X235\n",
      "520X236\n",
      "520X237\n",
      "520X238\n",
      "520X239\n",
      "520X240\n",
      "520X241\n",
      "520X242\n",
      "520X243\n",
      "520X244\n",
      "520X245\n",
      "520X252\n",
      "520X253\n",
      "520X254\n",
      "520X255\n",
      "520X256\n",
      "520X257\n",
      "520X258\n",
      "520X259\n",
      "520X260\n",
      "520X261\n",
      "520X262\n",
      "520X263\n",
      "520X264\n",
      "520X265\n",
      "520X266\n",
      "520X267\n",
      "520X281\n",
      "520X282\n",
      "520X283\n",
      "520X284\n",
      "520X285\n",
      "520X287\n",
      "520X288\n",
      "520X289\n",
      "520X290\n",
      "520X291\n",
      "520X293\n",
      "520X294\n",
      "520X295\n",
      "520X296\n",
      "520X297\n",
      "520X305\n",
      "520X306\n",
      "520X307\n",
      "520X308\n",
      "520X309\n",
      "520X311\n",
      "520X312\n",
      "520X313\n",
      "520X314\n",
      "520X315\n",
      "520X317\n",
      "520X318\n",
      "520X319\n",
      "520X320\n",
      "520X321\n",
      "520X323\n",
      "520X324\n",
      "520X325\n",
      "520X326\n",
      "520X327\n",
      "520X329\n",
      "520X330\n",
      "520X331\n",
      "520X332\n",
      "520X333\n",
      "520X380\n",
      "520X381\n",
      "520X387\n",
      "520X388\n",
      "520X389\n",
      "520X390\n",
      "520X391\n",
      "520X392\n",
      "520X393\n",
      "520X394\n",
      "520X395\n",
      "520X396\n",
      "520X397\n",
      "520X399\n",
      "520X400\n",
      "520X403\n",
      "520X404\n",
      "520X405\n",
      "520X406\n",
      "520X407\n",
      "520X408\n",
      "520X409\n",
      "520X410\n",
      "520X411\n",
      "520X412\n",
      "520X432\n",
      "210X13\n",
      "210X14\n",
      "210X15\n",
      "210X16\n",
      "210X25\n",
      "210X26\n",
      "210X27\n",
      "210X28\n",
      "210X32\n",
      "210X33\n",
      "210X34\n",
      "210X35\n",
      "210X40\n",
      "210X41\n",
      "210X42\n",
      "210X43\n",
      "210X44\n",
      "210X45\n",
      "210X46\n",
      "210X47\n",
      "210X48\n",
      "210X49\n",
      "210X50\n",
      "210X51\n",
      "210X53\n",
      "210X54\n",
      "210X55\n",
      "210X56\n",
      "210X57\n",
      "210X58\n",
      "210X59\n",
      "210X60\n",
      "210X61\n",
      "210X62\n",
      "210X63\n",
      "210X64\n",
      "210X65\n",
      "210X66\n",
      "210X67\n",
      "210X68\n",
      "210X69\n",
      "210X70\n",
      "210X71\n",
      "210X72\n",
      "210X73\n",
      "210X74\n",
      "210X75\n",
      "210X76\n",
      "210X81\n",
      "210X82\n",
      "210X83\n",
      "210X84\n",
      "210X85\n",
      "210X86\n",
      "210X87\n",
      "210X88\n",
      "210X112\n",
      "210X113\n",
      "210X114\n",
      "210X115\n",
      "210X116\n",
      "210X117\n",
      "210X118\n",
      "210X119\n",
      "210X120\n",
      "210X121\n",
      "210X122\n",
      "210X123\n",
      "210X124\n",
      "210X125\n",
      "210X126\n",
      "210X127\n",
      "210X128\n",
      "210X129\n",
      "210X130\n",
      "210X131\n",
      "210X132\n",
      "210X133\n",
      "210X134\n",
      "210X135\n",
      "210X136\n",
      "210X137\n",
      "210X138\n",
      "210X139\n",
      "210X140\n",
      "210X141\n",
      "210X142\n",
      "210X143\n",
      "210X144\n",
      "210X145\n",
      "210X146\n",
      "210X147\n",
      "210X148\n",
      "210X149\n",
      "210X150\n",
      "210X151\n",
      "210X153\n",
      "210X154\n",
      "210X155\n",
      "210X156\n",
      "210X157\n",
      "210X158\n",
      "210X159\n",
      "210X160\n",
      "210X161\n",
      "210X162\n",
      "210X163\n",
      "210X164\n",
      "210X165\n",
      "210X166\n",
      "210X167\n",
      "210X168\n",
      "210X169\n",
      "210X170\n",
      "210X171\n",
      "210X172\n",
      "210X173\n",
      "210X174\n",
      "210X175\n",
      "210X176\n",
      "210X177\n",
      "210X178\n",
      "210X179\n",
      "210X182\n",
      "210X200\n",
      "210X201\n",
      "210X202\n",
      "210X203\n",
      "210X211\n",
      "210X212\n",
      "520X1\n",
      "520X3\n",
      "520X6\n",
      "520X7\n",
      "520X8\n",
      "520X11\n",
      "520X12\n",
      "520X13\n",
      "520X16\n",
      "520X17\n",
      "520X18\n",
      "520X19\n",
      "520X21\n",
      "520X22\n",
      "520X23\n",
      "520X24\n",
      "520X26\n",
      "520X27\n",
      "520X28\n",
      "520X29\n",
      "520X31\n",
      "520X32\n",
      "520X33\n",
      "520X36\n",
      "520X37\n",
      "520X38\n",
      "520X41\n",
      "520X42\n",
      "520X43\n",
      "520X44\n",
      "520X46\n",
      "520X47\n",
      "520X48\n",
      "520X49\n",
      "520X51\n",
      "520X52\n",
      "520X53\n",
      "520X56\n",
      "520X57\n",
      "520X58\n",
      "520X61\n",
      "520X62\n",
      "520X63\n",
      "520X64\n",
      "520X66\n",
      "520X67\n",
      "520X68\n",
      "520X71\n",
      "520X72\n",
      "520X73\n",
      "520X76\n",
      "520X77\n",
      "520X78\n",
      "520X81\n",
      "520X82\n",
      "520X83\n",
      "520X86\n",
      "520X87\n",
      "520X88\n",
      "520X91\n",
      "520X92\n",
      "520X93\n",
      "520X96\n",
      "520X97\n",
      "520X98\n",
      "520X101\n",
      "520X102\n",
      "520X103\n",
      "520X106\n",
      "520X107\n",
      "520X108\n",
      "520X112\n",
      "520X113\n",
      "520X118\n",
      "520X119\n",
      "520X123\n",
      "520X124\n",
      "520X129\n",
      "520X130\n",
      "520X134\n",
      "520X135\n",
      "520X137\n",
      "300X11\n",
      "750X1\n",
      "750X2\n",
      "750X23\n",
      "750X24\n",
      "750X27\n",
      "750X34\n",
      "750X45\n",
      "750X46\n",
      "750X49\n",
      "750X57\n",
      "750X60\n",
      "750X90\n",
      "750X103\n",
      "750X109\n",
      "750X111\n",
      "750X115\n",
      "750X116\n",
      "750X118\n",
      "750X124\n",
      "750X131\n",
      "750X132\n",
      "750X140\n",
      "750X148\n",
      "750X155\n",
      "750X156\n",
      "750X164\n",
      "750X175\n",
      "750X185\n",
      "750X186\n",
      "750X197\n",
      "750X210\n",
      "750X218\n",
      "750X228\n",
      "750X229\n",
      "750X240\n",
      "750X251\n",
      "750X261\n",
      "750X262\n",
      "750X273\n",
      "750X284\n",
      "750X294\n",
      "750X295\n",
      "750X306\n",
      "750X317\n",
      "750X327\n",
      "750X328\n",
      "750X335\n",
      "750X336\n",
      "750X347\n",
      "750X358\n",
      "750X368\n",
      "750X369\n",
      "750X380\n",
      "750X391\n",
      "750X401\n",
      "750X402\n",
      "750X413\n",
      "750X424\n",
      "750X434\n",
      "750X435\n",
      "750X446\n",
      "750X454\n",
      "750X465\n",
      "750X476\n",
      "750X487\n",
      "750X498\n",
      "750X508\n",
      "750X509\n",
      "750X520\n",
      "750X531\n",
      "750X541\n",
      "750X542\n",
      "750X553\n",
      "750X564\n",
      "750X572\n",
      "750X582\n",
      "750X583\n",
      "750X594\n",
      "750X604\n",
      "750X611\n",
      "750X612\n",
      "750X620\n",
      "750X628\n",
      "750X635\n",
      "750X636\n",
      "750X644\n",
      "750X652\n",
      "750X659\n",
      "750X660\n",
      "750X668\n",
      "750X676\n",
      "750X691\n",
      "750X697\n",
      "750X702\n",
      "750X705\n",
      "750X712\n",
      "750X713\n",
      "750X741\n",
      "750X742\n",
      "750X745\n",
      "750X763\n",
      "750X764\n",
      "750X775\n",
      "750X778\n",
      "750X785\n",
      "750X789\n",
      "750X971\n",
      "750X986\n",
      "750X988\n",
      "750X996\n",
      "750X1002\n",
      "750X1005\n",
      "750X1008\n",
      "750X1019\n",
      "750X1030\n",
      "750X1041\n",
      "750X1049\n",
      "750X1052\n",
      "750X1071\n",
      "750X1074\n",
      "750X1096\n",
      "750X1115\n",
      "750X1129\n",
      "750X1137\n",
      "750X1139\n",
      "750X1164\n",
      "750X1189\n",
      "750X1192\n",
      "750X1203\n",
      "750X1225\n",
      "750X1247\n",
      "750X1288\n",
      "750X1296\n",
      "750X1298\n",
      "750X1306\n",
      "750X1312\n",
      "750X1314\n",
      "750X1330\n",
      "750X1357\n",
      "750X1384\n",
      "300X1\n",
      "300X21\n",
      "300X2\n",
      "300X8\n",
      "312X70\n",
      "312X71\n",
      "312X72\n",
      "312X76\n",
      "312X77\n",
      "312X78\n",
      "312X81\n",
      "312X82\n",
      "312X83\n",
      "312X84\n",
      "210X1\n",
      "210X2\n",
      "210X3\n",
      "210X4\n",
      "210X5\n",
      "210X6\n",
      "210X11\n",
      "210X12\n",
      "210X39\n",
      "210X52\n",
      "210X209\n",
      "210X210\n",
      "400X141\n",
      "311X4\n",
      "311X8\n",
      "311X10\n",
      "311X12\n",
      "311X16\n",
      "311X18\n",
      "311X20\n",
      "311X22\n",
      "210X228\n",
      "210X229\n",
      "210X230\n",
      "210X231\n",
      "330X35\n",
      "330X38\n",
      "330X101\n",
      "330X103\n",
      "330X627\n",
      "330X629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330X631\n",
      "330X634\n",
      "330X749\n",
      "311X69\n",
      "311X157\n",
      "261X343\n",
      "261X529\n",
      "261X715\n",
      "311X66\n",
      "311X154\n",
      "261X340\n",
      "261X526\n",
      "261X712\n",
      "311X27\n",
      "312X55\n",
      "312X61\n",
      "312X67\n",
      "312X73\n",
      "312X79\n",
      "312X85\n",
      "312X91\n",
      "312X97\n",
      "312X115\n",
      "312X121\n",
      "312X127\n",
      "312X133\n",
      "312X139\n",
      "312X145\n",
      "312X163\n",
      "312X169\n",
      "312X175\n",
      "312X187\n",
      "312X193\n",
      "312X199\n",
      "312X211\n",
      "312X217\n",
      "312X223\n",
      "312X235\n",
      "312X240\n",
      "312X246\n",
      "312X257\n",
      "312X263\n",
      "312X269\n",
      "312X281\n",
      "312X287\n",
      "312X293\n",
      "312X311\n",
      "312X335\n",
      "312X341\n",
      "312X353\n",
      "312X359\n",
      "312X365\n",
      "312X377\n",
      "312X383\n",
      "312X389\n",
      "312X430\n",
      "312X436\n",
      "312X442\n",
      "312X448\n",
      "312X478\n",
      "312X520\n",
      "312X574\n",
      "312X580\n",
      "312X586\n",
      "312X592\n",
      "312X598\n",
      "312X634\n",
      "312X640\n",
      "312X670\n",
      "312X676\n",
      "312X682\n",
      "312X694\n",
      "312X699\n",
      "312X704\n",
      "312X714\n",
      "312X720\n",
      "312X726\n",
      "312X732\n",
      "312X738\n",
      "312X744\n",
      "312X762\n",
      "312X768\n",
      "312X774\n",
      "312X780\n",
      "312X786\n",
      "312X792\n",
      "220X289\n",
      "220X485\n",
      "220X526\n",
      "220X554\n",
      "344X270\n",
      "344X306\n",
      "220X551\n",
      "220X557\n"
     ]
    }
   ],
   "source": [
    "used_list = null_dict[0]\n",
    "for key in keys:\n",
    "    if key==0:\n",
    "        continue\n",
    "    for var in null_dict[key]:\n",
    "        dfAll_input = dfAll[used_list]\n",
    "        train = dfAll_input.loc[dfAll[var].notnull()]\n",
    "        target = dfAll.loc[dfAll[var].notnull(),var]\n",
    "        test = dfAll_input.loc[dfAll[var].isnull()]\n",
    "        model = RandomForestRegressor(n_estimators=1999, max_features='sqrt',  max_depth=4, random_state=615)  \n",
    "        model.fit(train,target)\n",
    "        predicted = model.predict(test)\n",
    "        dfAll.loc[dfAll[var].isnull(),var] = predicted\n",
    "        print(var)\n",
    "        used_list.append(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAll.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfAll3.to_csv('../../Data/All_non_missing.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(721, 3293)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print(\"Load data...\")\n",
    "\n",
    "dfTrain = pd.read_csv(config.original_train_data_path)\n",
    "\n",
    "dfPred= pd.read_csv(config.original_test_data_path)\n",
    "dfPred2= pd.read_csv(config.original_test_data2_path)\n",
    "# number of train/test samples\n",
    "num_train, num_pred = dfTrain.shape[0], dfPred.shape[0]\n",
    "\n",
    "print(\"Done.\")\n",
    "\n",
    "f = open('../../Data/col_name.txt','r')  \n",
    "a = f.read()  \n",
    "col_name = eval(a)  \n",
    "f.close() \n",
    "\n",
    "f = open('../../Data/Procedure.txt','r')  \n",
    "a = f.read()  \n",
    "procedure = eval(a)  \n",
    "f.close()\n",
    "\n",
    "f = open('../../Cache/var_change.txt','r')\n",
    "a = f.read()\n",
    "var_change = eval(a)\n",
    "f.close()\n",
    "\n",
    "dfTrain = dfTrain.rename(columns=col_name)\n",
    "raw_predictors = dfTrain.columns.tolist()[1:-1]\n",
    "dfTrain = dfTrain.set_index(dfTrain['ID'])\n",
    "dfPred = dfPred.rename(columns=col_name)\n",
    "dfPred = dfPred.set_index(dfPred['ID'])\n",
    "dfPred2 = dfPred2.rename(columns=col_name)\n",
    "\n",
    "dfPredAll = pd.concat([dfPred,dfPred2],axis=0)\n",
    "dfPredAll = dfPredAll.set_index(dfPredAll['ID'])\n",
    "\n",
    "dfAll = pd.concat([dfTrain,dfPred,dfPred2],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load features\n",
    "Feat_file = ['Feat_cnt_col','Feat_cnt_tool','Feat_pcent_col','Feat_pcent_tool']\n",
    "ex_feat = []\n",
    "for filename in Feat_file:\n",
    "    tmp = pd.read_csv('../../Cache/'+filename+'.csv')\n",
    "    tmp.set_index(tmp['ID'],inplace=True,drop=True)\n",
    "    tmp_feat_list = tmp.columns.tolist()\n",
    "    if 'ID' in tmp_feat_list:\n",
    "        tmp_feat_list.remove('ID')\n",
    "    ex_feat += tmp_feat_list\n",
    "    dfTrain = pd.merge(dfTrain,tmp,'left','ID')\n",
    "    dfPred = pd.merge(dfPred,tmp,'left','ID')\n",
    "   \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##define the variables\n",
    "'''var_change = {'raw':raw}\n",
    "for filename in Feat_file:\n",
    "    tmp = pd.read_csv('../../Cache/'+filename+'.csv',nrows=10)\n",
    "    tmp.set_index(tmp['ID'],inplace=True,drop=True)\n",
    "    tmp_feat_list = tmp.columns.tolist()\n",
    "    if 'ID' in tmp_feat_list:\n",
    "        tmp_feat_list.remove('ID')\n",
    "    var_change[filename] = {'constant':[],'category':[]}\n",
    "    for var in tmp_feat_list:\n",
    "        if dfTrain[var].nunique()==1 and dfTrain[var].isnull().sum()==0:\n",
    "            var_change[filename]['constant'].append(var)\n",
    "        elif dfTrain[var].nunique()<=5 or 'TOOL' in var:\n",
    "            var_change[filename]['category'].append(var)\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define the input variables, dummies\n",
    "predictors = raw_predictors+ex_feat\n",
    "feat_cnt = 0\n",
    "for key,value in var_change.items():\n",
    "    feat_cnt+=1\n",
    "    if feat_cnt>1:\n",
    "        continue\n",
    "    for var in var_change[key]['constant']:\n",
    "        predictors.remove(var)\n",
    "    for var in var_change[key]['category']:\n",
    "        predictors.remove(var)\n",
    "        tmpTrain = pd.get_dummies(dfTrain[var],prefix=var,dummy_na=True)\n",
    "        tmpPred = pd.get_dummies(dfPred[var],prefix=var,dummy_na=True)\n",
    "        predictors = predictors + tmpTrain.columns.tolist()\n",
    "        dfTrain = pd.concat([dfTrain,tmpTrain],axis=1)\n",
    "        dfPred = pd.concat([dfPred,tmpPred],axis=1)\n",
    "for var in predictors:\n",
    "    if var not in dfPred.columns:\n",
    "        dfPred[var] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgb_kfold(dfTrain,dfPred,predictors,n_splits=5, params = {'max_depth':4, 'eta':0.01, 'silent':0,'objective':'reg:linear','lambda':2,'subsample':0.8,\n",
    "                         'colsample_bytree':0.8}):  \n",
    "    kf = KFold(n_splits=n_splits,shuffle=True)\n",
    "    dpred = xgb.DMatrix(dfPred[predictors].values,label=[0]*len(dfPred),missing=np.nan)\n",
    "    imp = pd.DataFrame({'variable':predictors,'lk':['f'+str(i) for i in range(len(predictors))]})\n",
    "    round=0\n",
    "    for train_index, test_index in kf.split(dfTrain):\n",
    "        round+=1\n",
    "        train_X = dfTrain.loc[train_index,predictors]\n",
    "        test_X = dfTrain.loc[test_index,predictors]\n",
    "        train_Y = dfTrain.loc[train_index,'Y']\n",
    "        test_Y = dfTrain.loc[test_index,'Y']\n",
    "\n",
    "        dtrain = xgb.DMatrix(train_X.values, label=train_Y.values, missing = np.nan)\n",
    "        dtest = xgb.DMatrix(test_X.values, label=test_Y.values, missing = np.nan)\n",
    "        param = params \n",
    "        evallist  = [(dtrain,'train'),(dtest,'eval')]  \n",
    "        num_round = 5000\n",
    "        evals_dict = {}\n",
    "        model = xgb.train(param,dtrain,num_round, evallist,early_stopping_rounds=50,evals_result=evals_dict,verbose_eval =1000)\n",
    "        performance_df = pd.DataFrame(evals_dict['eval'])\n",
    "        bst_tree = len(performance_df)-51\n",
    "        pred_test = model.predict(dtest,ntree_limit =bst_tree)\n",
    "\n",
    "        tmp_imp = pd.DataFrame(model.get_score(importance_type='gain'),index=['imp_fold%d'%round]).T\n",
    "        tmp_imp['lk'] = tmp_imp.index\n",
    "        imp = imp.merge(tmp_imp,'left','lk').fillna(0)\n",
    "\n",
    "\n",
    "        pred_score = model.predict(dpred,ntree_limit =bst_tree)\n",
    "        if round==1:\n",
    "            test_result = pd.DataFrame({'ID':dfTrain.loc[test_index,'ID'].values,'score':pred_test,'target':test_Y})\n",
    "            result = pd.DataFrame({'ID':dfPred['ID'],'Score_%d'%round:pred_score})\n",
    "        else:\n",
    "            test_result = pd.concat([test_result,pd.DataFrame({'ID':dfTrain.loc[test_index,'ID'].values,'score':pred_test,'target':test_Y})],axis=0)\n",
    "            result = result.merge(pd.DataFrame({'ID':dfPred['ID'],'Score_%d'%round:pred_score}),'inner','ID')\n",
    "    print(\"Test MSE:\",metrics.mean_squared_error(test_result['target'], test_result['score']))\n",
    "    return test_result,result,imp,metrics.mean_squared_error(test_result['target'], test_result['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 0.8, 0.6, 0.2]\n",
      "[0]\ttrain-rmse:2.33435\teval-rmse:2.31993\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[508]\ttrain-rmse:0.080587\teval-rmse:0.17733\n",
      "\n",
      "[0]\ttrain-rmse:2.32603\teval-rmse:2.35314\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 50 rounds.\n",
      "[1000]\ttrain-rmse:0.036267\teval-rmse:0.190875\n",
      "Stopping. Best iteration:\n",
      "[964]\ttrain-rmse:0.038393\teval-rmse:0.19084\n",
      "\n",
      "[0]\ttrain-rmse:2.3309\teval-rmse:2.33339\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[626]\ttrain-rmse:0.067672\teval-rmse:0.14085\n",
      "\n",
      "[0]\ttrain-rmse:2.32928\teval-rmse:2.34094\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[702]\ttrain-rmse:0.058056\teval-rmse:0.166757\n",
      "\n",
      "[0]\ttrain-rmse:2.33676\teval-rmse:2.30969\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[543]\ttrain-rmse:0.075816\teval-rmse:0.187679\n",
      "\n",
      "Test MSE: 0.0301560999918\n",
      "[3, 0.8, 0.6, 0.4]\n",
      "[0]\ttrain-rmse:2.33296\teval-rmse:2.32607\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[584]\ttrain-rmse:0.070719\teval-rmse:0.147349\n",
      "\n",
      "[0]\ttrain-rmse:2.32895\teval-rmse:2.34105\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 50 rounds.\n"
     ]
    }
   ],
   "source": [
    "record = []\n",
    "for md in [3,4,5]:\n",
    "    for la in [0.8,1,1.3,1.5,2]:\n",
    "        for sp in [0.6,0.8,1]:\n",
    "            for cb in [0.2,0.4,0.6,0.8,1]:\n",
    "                tmp_record = [md,la,sp,cb]\n",
    "                print(tmp_record)\n",
    "                params = {'max_depth':md, 'eta':0.01, 'silent':0,'objective':'reg:linear','lambda':la,'subsample':sp,'colsample_bytree':cb}\n",
    "                tmp_record.append(xgb_kfold(dfTrain,dfPred,predictors,5,params=params)[3])\n",
    "                record.append(tmp_record)\n",
    "                GS_df = pd.DataFrame(record,columns=['max_depth','lambda','subsample','colsample_bytree','test_MSE'])\n",
    "                GS_df.to_csv('../../Profiling/GS_result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:2.33325\teval-rmse:2.32446\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 50 rounds.\n",
      "[50]\ttrain-rmse:1.42504\teval-rmse:1.41672\n",
      "[100]\ttrain-rmse:0.879138\teval-rmse:0.872982\n",
      "[150]\ttrain-rmse:0.55208\teval-rmse:0.555279\n",
      "[200]\ttrain-rmse:0.355857\teval-rmse:0.372674\n",
      "[250]\ttrain-rmse:0.236805\teval-rmse:0.272561\n",
      "[300]\ttrain-rmse:0.163235\teval-rmse:0.220306\n",
      "[350]\ttrain-rmse:0.117279\teval-rmse:0.19572\n",
      "[400]\ttrain-rmse:0.088505\teval-rmse:0.184687\n",
      "[450]\ttrain-rmse:0.069554\teval-rmse:0.180748\n",
      "[500]\ttrain-rmse:0.056817\teval-rmse:0.178809\n",
      "[550]\ttrain-rmse:0.047473\teval-rmse:0.17801\n",
      "[600]\ttrain-rmse:0.04041\teval-rmse:0.177439\n",
      "[650]\ttrain-rmse:0.034622\teval-rmse:0.17706\n",
      "[700]\ttrain-rmse:0.029927\teval-rmse:0.177028\n",
      "[750]\ttrain-rmse:0.025907\teval-rmse:0.176934\n",
      "[800]\ttrain-rmse:0.022595\teval-rmse:0.176859\n",
      "[850]\ttrain-rmse:0.019805\teval-rmse:0.176851\n",
      "Stopping. Best iteration:\n",
      "[819]\ttrain-rmse:0.021476\teval-rmse:0.17677\n",
      "\n",
      "[0]\ttrain-rmse:2.33442\teval-rmse:2.31983\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 50 rounds.\n",
      "[50]\ttrain-rmse:1.42637\teval-rmse:1.41143\n",
      "[100]\ttrain-rmse:0.880018\teval-rmse:0.867547\n",
      "[150]\ttrain-rmse:0.552915\teval-rmse:0.548479\n",
      "[200]\ttrain-rmse:0.356164\teval-rmse:0.365074\n",
      "[250]\ttrain-rmse:0.235907\teval-rmse:0.266178\n",
      "[300]\ttrain-rmse:0.161699\teval-rmse:0.217447\n",
      "[350]\ttrain-rmse:0.116264\teval-rmse:0.196616\n",
      "[400]\ttrain-rmse:0.08721\teval-rmse:0.187602\n",
      "[450]\ttrain-rmse:0.068744\teval-rmse:0.184633\n",
      "[500]\ttrain-rmse:0.056519\teval-rmse:0.183847\n",
      "[550]\ttrain-rmse:0.047605\teval-rmse:0.183498\n",
      "[600]\ttrain-rmse:0.040708\teval-rmse:0.183611\n",
      "Stopping. Best iteration:\n",
      "[550]\ttrain-rmse:0.047605\teval-rmse:0.183498\n",
      "\n",
      "[0]\ttrain-rmse:2.32128\teval-rmse:2.37266\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 50 rounds.\n",
      "[50]\ttrain-rmse:1.41768\teval-rmse:1.46923\n",
      "[100]\ttrain-rmse:0.874397\teval-rmse:0.926371\n",
      "[150]\ttrain-rmse:0.550305\teval-rmse:0.60405\n",
      "[200]\ttrain-rmse:0.355075\teval-rmse:0.414502\n",
      "[250]\ttrain-rmse:0.235515\teval-rmse:0.307053\n",
      "[300]\ttrain-rmse:0.162647\teval-rmse:0.248968\n",
      "[350]\ttrain-rmse:0.116702\teval-rmse:0.219699\n",
      "[400]\ttrain-rmse:0.088322\teval-rmse:0.204807\n",
      "[450]\ttrain-rmse:0.069256\teval-rmse:0.197488\n",
      "[500]\ttrain-rmse:0.056755\teval-rmse:0.193662\n",
      "[550]\ttrain-rmse:0.04805\teval-rmse:0.191852\n",
      "[600]\ttrain-rmse:0.041349\teval-rmse:0.190863\n",
      "[650]\ttrain-rmse:0.035509\teval-rmse:0.190005\n",
      "[700]\ttrain-rmse:0.0308\teval-rmse:0.189742\n",
      "[750]\ttrain-rmse:0.02668\teval-rmse:0.189272\n",
      "[800]\ttrain-rmse:0.023137\teval-rmse:0.189192\n",
      "[850]\ttrain-rmse:0.020157\teval-rmse:0.18901\n",
      "Stopping. Best iteration:\n",
      "[831]\ttrain-rmse:0.021132\teval-rmse:0.188983\n",
      "\n",
      "[0]\ttrain-rmse:2.33315\teval-rmse:2.3247\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 50 rounds.\n",
      "[50]\ttrain-rmse:1.42498\teval-rmse:1.41655\n",
      "[100]\ttrain-rmse:0.879532\teval-rmse:0.873154\n",
      "[150]\ttrain-rmse:0.55311\teval-rmse:0.554023\n",
      "[200]\ttrain-rmse:0.356215\teval-rmse:0.370517\n",
      "[250]\ttrain-rmse:0.236455\teval-rmse:0.269497\n",
      "[300]\ttrain-rmse:0.162869\teval-rmse:0.217386\n",
      "[350]\ttrain-rmse:0.116988\teval-rmse:0.192301\n",
      "[400]\ttrain-rmse:0.087698\teval-rmse:0.180854\n",
      "[450]\ttrain-rmse:0.069074\teval-rmse:0.175795\n",
      "[500]\ttrain-rmse:0.056505\teval-rmse:0.173312\n",
      "[550]\ttrain-rmse:0.047347\teval-rmse:0.172125\n",
      "[600]\ttrain-rmse:0.040307\teval-rmse:0.171255\n",
      "[650]\ttrain-rmse:0.034436\teval-rmse:0.17082\n",
      "[700]\ttrain-rmse:0.029959\teval-rmse:0.170616\n",
      "[750]\ttrain-rmse:0.026083\teval-rmse:0.170547\n",
      "[800]\ttrain-rmse:0.022712\teval-rmse:0.170376\n",
      "[850]\ttrain-rmse:0.019694\teval-rmse:0.170312\n",
      "Stopping. Best iteration:\n",
      "[819]\ttrain-rmse:0.021477\teval-rmse:0.170252\n",
      "\n",
      "[0]\ttrain-rmse:2.33556\teval-rmse:2.31557\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 50 rounds.\n",
      "[50]\ttrain-rmse:1.42643\teval-rmse:1.40585\n",
      "[100]\ttrain-rmse:0.880586\teval-rmse:0.86033\n",
      "[150]\ttrain-rmse:0.553593\teval-rmse:0.542548\n",
      "[200]\ttrain-rmse:0.35683\teval-rmse:0.357494\n",
      "[250]\ttrain-rmse:0.237037\teval-rmse:0.254259\n",
      "[300]\ttrain-rmse:0.163012\teval-rmse:0.200446\n",
      "[350]\ttrain-rmse:0.117768\teval-rmse:0.173518\n",
      "[400]\ttrain-rmse:0.089302\teval-rmse:0.16171\n",
      "[450]\ttrain-rmse:0.070598\teval-rmse:0.15657\n",
      "[500]\ttrain-rmse:0.058014\teval-rmse:0.153563\n",
      "[550]\ttrain-rmse:0.048865\teval-rmse:0.1525\n",
      "[600]\ttrain-rmse:0.041959\teval-rmse:0.151907\n",
      "[650]\ttrain-rmse:0.03635\teval-rmse:0.151331\n",
      "[700]\ttrain-rmse:0.031464\teval-rmse:0.151055\n",
      "[750]\ttrain-rmse:0.027272\teval-rmse:0.150873\n",
      "[800]\ttrain-rmse:0.023755\teval-rmse:0.150768\n",
      "[850]\ttrain-rmse:0.020823\teval-rmse:0.150581\n",
      "[900]\ttrain-rmse:0.018146\teval-rmse:0.150402\n",
      "[950]\ttrain-rmse:0.015977\teval-rmse:0.150459\n",
      "Stopping. Best iteration:\n",
      "[901]\ttrain-rmse:0.018095\teval-rmse:0.1504\n",
      "\n",
      "Test MSE: 0.0304553713821\n"
     ]
    }
   ],
   "source": [
    "test_result,result,imp = xgb_kfold(dfTrain,dfPred,predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp.to_csv('../../Profiling/imp_test_v3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result['score']=result[['Score_1','Score_2','Score_3','Score_4','Score_5']].mean(axis=1)\n",
    "submit = result[['ID','score']]\n",
    "today = datetime.date.today().strftime('%Y-%m-%d')\n",
    "submit.to_csv('../../Submission/submit_%s.csv'%today,header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#貌似RF根本就不需要CV啊，其实也行吧\n",
    "def rf_kfold(dfTrain,dfPred,predictors,n_splits=5):  \n",
    "    kf = KFold(n_splits=n_splits,shuffle=True)\n",
    "    dpred = xgb.DMatrix(dfPred[predictors].values,label=[0]*len(dfPred),missing=np.nan)\n",
    "    imp = pd.DataFrame({'variable':predictors,'lk':['f'+str(i) for i in range(len(predictors))]})\n",
    "    round=0\n",
    "    for train_index, test_index in kf.split(dfTrain):\n",
    "        round+=1\n",
    "        train_X = dfTrain.loc[train_index,predictors].values\n",
    "        test_X = dfTrain.loc[test_index,predictors].values\n",
    "        train_Y = dfTrain.loc[train_index,'Y'].values\n",
    "        test_Y = dfTrain.loc[test_index,'Y'].values\n",
    " \n",
    "        model = RandomForestRegressor(n_estimators=1999, max_features='sqrt', max_depth=None, max_depth=4, compute_importances=True, random_state=615)  \n",
    "        model.fit(train_X,train_Y)\n",
    "        pred_test = model.predict(test_X）\n",
    "        pred_score = model.predict(dfPred[predictors].values)\n",
    "        if round==1:\n",
    "            test_result = pd.DataFrame({'ID':dfTrain.loc[test_index,'ID'].values,'score':pred_test,'target':test_Y})\n",
    "            result = pd.DataFrame({'ID':dfPred['ID'],'Score_%d'%round:pred_score})\n",
    "        else:\n",
    "            test_result = pd.concat([test_result,pd.DataFrame({'ID':dfTrain.loc[test_index,'ID'].values,'score':pred_test,'target':test_Y})],axis=0)\n",
    "            result = result.merge(pd.DataFrame({'ID':dfPred['ID'],'Score_%d'%round:pred_score}),'inner','ID')\n",
    "    print(\"Test MSE:\",metrics.mean_squared_error(test_result['target'], test_result['score']))\n",
    "    return test_result,result,imp,metrics.mean_squared_error(test_result['target'], test_result['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RF填缺失值"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
