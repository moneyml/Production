{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from nlp_utils import clean_text, pos_tag_text\n",
    "sys.path.append(\"../\")\n",
    "from param_config import config\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "import datetime\n",
    "\n",
    "pd.set_option('display.float_format',lambda x: '%.5f'%x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfAll = pd.read_csv('../../Data/All_Data_dedup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfAll2 = pd.read_csv('../../Data/All_Data_dedup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for var in dfAll.columns:\n",
    "    if 'TOOL' in var:\n",
    "        tmpTrain = pd.get_dummies(dfAll[var],prefix=var,dummy_na=True)\n",
    "        dfAll = pd.concat([dfAll,tmpTrain],axis=1)\n",
    "        del dfAll[var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = dfAll.isnull().sum().to_dict()\n",
    "null_dict ={}\n",
    "for key,value in tmp.items():\n",
    "    if key=='ID':\n",
    "        continue\n",
    "    if not null_dict.__contains__(value):\n",
    "        null_dict[value] = [key]\n",
    "    else:\n",
    "        null_dict[value].append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220X25\n",
      "220X26\n",
      "220X27\n",
      "220X28\n",
      "220X29\n",
      "220X30\n",
      "220X31\n",
      "220X32\n",
      "220X33\n",
      "220X34\n",
      "220X35\n",
      "220X36\n",
      "220X37\n",
      "220X38\n",
      "220X39\n",
      "220X40\n",
      "220X53\n",
      "220X54\n",
      "220X55\n",
      "220X67\n",
      "220X107\n",
      "220X108\n",
      "220X222\n",
      "220X223\n",
      "220X224\n",
      "220X225\n",
      "220X241\n",
      "220X247\n",
      "220X248\n",
      "220X249\n",
      "220X260\n",
      "220X262\n",
      "220X266\n",
      "220X269\n",
      "220X270\n",
      "220X271\n",
      "220X272\n",
      "220X273\n",
      "220X274\n",
      "220X275\n",
      "220X277\n",
      "220X279\n",
      "220X281\n",
      "220X282\n",
      "220X284\n",
      "220X286\n",
      "220X288\n",
      "220X289\n",
      "220X290\n",
      "220X291\n",
      "220X293\n",
      "220X294\n",
      "220X295\n",
      "220X296\n",
      "220X297\n",
      "220X298\n",
      "220X299\n",
      "220X300\n",
      "220X301\n",
      "220X302\n",
      "220X303\n",
      "220X304\n",
      "220X305\n",
      "220X306\n",
      "220X307\n",
      "220X308\n",
      "220X309\n",
      "220X310\n",
      "220X311\n",
      "220X312\n",
      "220X313\n",
      "220X314\n",
      "220X315\n",
      "220X316\n",
      "220X317\n",
      "220X318\n",
      "220X321\n",
      "220X322\n",
      "220X323\n",
      "220X324\n",
      "220X325\n",
      "220X326\n",
      "220X327\n",
      "220X328\n",
      "220X329\n",
      "220X330\n",
      "220X331\n",
      "220X332\n",
      "220X333\n",
      "220X334\n",
      "220X335\n",
      "220X336\n",
      "220X337\n",
      "220X338\n",
      "220X339\n",
      "220X340\n",
      "220X341\n",
      "220X342\n",
      "220X343\n",
      "220X344\n",
      "220X345\n",
      "220X346\n",
      "220X347\n",
      "220X348\n",
      "220X349\n",
      "220X350\n",
      "220X351\n",
      "220X352\n",
      "220X353\n",
      "220X354\n",
      "220X355\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-9c5ffe2980c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfAll_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdfAll\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1999\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sqrt'\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m615\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mdfAll\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdfAll\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 328\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1122\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1125\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dfAll_input = dfAll[null_dict[0]]\n",
    "for key,value in null_dict.items():\n",
    "    if key==0:\n",
    "        continue\n",
    "    for var in value:\n",
    "        train = dfAll_input.loc[dfAll[var].notnull()]\n",
    "        target = dfAll.loc[dfAll[var].notnull(),var]\n",
    "        test = dfAll_input.loc[dfAll[var].isnull()]\n",
    "        model = RandomForestRegressor(n_estimators=1999, max_features='sqrt',  max_depth=4, random_state=615)  \n",
    "        model.fit(train,target)\n",
    "        predicted = model.predict(test)\n",
    "        dfAll.loc[dfAll[var].isnull(),var] = predicted\n",
    "        print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print(\"Load data...\")\n",
    "\n",
    "dfTrain = pd.read_csv(config.original_train_data_path)\n",
    "\n",
    "dfPred= pd.read_csv(config.original_test_data_path)\n",
    "dfPred2= pd.read_csv(config.original_test_data2_path)\n",
    "# number of train/test samples\n",
    "num_train, num_pred = dfTrain.shape[0], dfPred.shape[0]\n",
    "\n",
    "print(\"Done.\")\n",
    "\n",
    "f = open('../../Data/col_name.txt','r')  \n",
    "a = f.read()  \n",
    "col_name = eval(a)  \n",
    "f.close() \n",
    "\n",
    "f = open('../../Data/Procedure.txt','r')  \n",
    "a = f.read()  \n",
    "procedure = eval(a)  \n",
    "f.close()\n",
    "\n",
    "f = open('../../Cache/var_change.txt','r')\n",
    "a = f.read()\n",
    "var_change = eval(a)\n",
    "f.close()\n",
    "\n",
    "dfTrain = dfTrain.rename(columns=col_name)\n",
    "raw_predictors = dfTrain.columns.tolist()[1:-1]\n",
    "dfTrain = dfTrain.set_index(dfTrain['ID'])\n",
    "dfPred = dfPred.rename(columns=col_name)\n",
    "dfPred = dfPred.set_index(dfPred['ID'])\n",
    "dfPred2 = dfPred2.rename(columns=col_name)\n",
    "\n",
    "dfPredAll = pd.concat([dfPred,dfPred2],axis=0)\n",
    "dfPredAll = dfPredAll.set_index(dfPredAll['ID'])\n",
    "\n",
    "dfAll = pd.concat([dfTrain,dfPred,dfPred2],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load features\n",
    "Feat_file = ['Feat_cnt_col','Feat_cnt_tool','Feat_pcent_col','Feat_pcent_tool']\n",
    "ex_feat = []\n",
    "for filename in Feat_file:\n",
    "    tmp = pd.read_csv('../../Cache/'+filename+'.csv')\n",
    "    tmp.set_index(tmp['ID'],inplace=True,drop=True)\n",
    "    tmp_feat_list = tmp.columns.tolist()\n",
    "    if 'ID' in tmp_feat_list:\n",
    "        tmp_feat_list.remove('ID')\n",
    "    ex_feat += tmp_feat_list\n",
    "    dfTrain = pd.merge(dfTrain,tmp,'left','ID')\n",
    "    dfPred = pd.merge(dfPred,tmp,'left','ID')\n",
    "   \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##define the variables\n",
    "'''var_change = {'raw':raw}\n",
    "for filename in Feat_file:\n",
    "    tmp = pd.read_csv('../../Cache/'+filename+'.csv',nrows=10)\n",
    "    tmp.set_index(tmp['ID'],inplace=True,drop=True)\n",
    "    tmp_feat_list = tmp.columns.tolist()\n",
    "    if 'ID' in tmp_feat_list:\n",
    "        tmp_feat_list.remove('ID')\n",
    "    var_change[filename] = {'constant':[],'category':[]}\n",
    "    for var in tmp_feat_list:\n",
    "        if dfTrain[var].nunique()==1 and dfTrain[var].isnull().sum()==0:\n",
    "            var_change[filename]['constant'].append(var)\n",
    "        elif dfTrain[var].nunique()<=5 or 'TOOL' in var:\n",
    "            var_change[filename]['category'].append(var)\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define the input variables, dummies\n",
    "predictors = raw_predictors+ex_feat\n",
    "feat_cnt = 0\n",
    "for key,value in var_change.items():\n",
    "    feat_cnt+=1\n",
    "    if feat_cnt>1:\n",
    "        continue\n",
    "    for var in var_change[key]['constant']:\n",
    "        predictors.remove(var)\n",
    "    for var in var_change[key]['category']:\n",
    "        predictors.remove(var)\n",
    "        tmpTrain = pd.get_dummies(dfTrain[var],prefix=var,dummy_na=True)\n",
    "        tmpPred = pd.get_dummies(dfPred[var],prefix=var,dummy_na=True)\n",
    "        predictors = predictors + tmpTrain.columns.tolist()\n",
    "        dfTrain = pd.concat([dfTrain,tmpTrain],axis=1)\n",
    "        dfPred = pd.concat([dfPred,tmpPred],axis=1)\n",
    "for var in predictors:\n",
    "    if var not in dfPred.columns:\n",
    "        dfPred[var] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgb_kfold(dfTrain,dfPred,predictors,n_splits=5, params = {'max_depth':4, 'eta':0.01, 'silent':0,'objective':'reg:linear','lambda':2,'subsample':0.8,\n",
    "                         'colsample_bytree':0.8}):  \n",
    "    kf = KFold(n_splits=n_splits,shuffle=True)\n",
    "    dpred = xgb.DMatrix(dfPred[predictors].values,label=[0]*len(dfPred),missing=np.nan)\n",
    "    imp = pd.DataFrame({'variable':predictors,'lk':['f'+str(i) for i in range(len(predictors))]})\n",
    "    round=0\n",
    "    for train_index, test_index in kf.split(dfTrain):\n",
    "        round+=1\n",
    "        train_X = dfTrain.loc[train_index,predictors]\n",
    "        test_X = dfTrain.loc[test_index,predictors]\n",
    "        train_Y = dfTrain.loc[train_index,'Y']\n",
    "        test_Y = dfTrain.loc[test_index,'Y']\n",
    "\n",
    "        dtrain = xgb.DMatrix(train_X.values, label=train_Y.values, missing = np.nan)\n",
    "        dtest = xgb.DMatrix(test_X.values, label=test_Y.values, missing = np.nan)\n",
    "        param = params \n",
    "        evallist  = [(dtrain,'train'),(dtest,'eval')]  \n",
    "        num_round = 5000\n",
    "        evals_dict = {}\n",
    "        model = xgb.train(param,dtrain,num_round, evallist,early_stopping_rounds=50,evals_result=evals_dict,verbose_eval =1000)\n",
    "        performance_df = pd.DataFrame(evals_dict['eval'])\n",
    "        bst_tree = len(performance_df)-51\n",
    "        pred_test = model.predict(dtest,ntree_limit =bst_tree)\n",
    "\n",
    "        tmp_imp = pd.DataFrame(model.get_score(importance_type='gain'),index=['imp_fold%d'%round]).T\n",
    "        tmp_imp['lk'] = tmp_imp.index\n",
    "        imp = imp.merge(tmp_imp,'left','lk').fillna(0)\n",
    "\n",
    "\n",
    "        pred_score = model.predict(dpred,ntree_limit =bst_tree)\n",
    "        if round==1:\n",
    "            test_result = pd.DataFrame({'ID':dfTrain.loc[test_index,'ID'].values,'score':pred_test,'target':test_Y})\n",
    "            result = pd.DataFrame({'ID':dfPred['ID'],'Score_%d'%round:pred_score})\n",
    "        else:\n",
    "            test_result = pd.concat([test_result,pd.DataFrame({'ID':dfTrain.loc[test_index,'ID'].values,'score':pred_test,'target':test_Y})],axis=0)\n",
    "            result = result.merge(pd.DataFrame({'ID':dfPred['ID'],'Score_%d'%round:pred_score}),'inner','ID')\n",
    "    print(\"Test MSE:\",metrics.mean_squared_error(test_result['target'], test_result['score']))\n",
    "    return test_result,result,imp,metrics.mean_squared_error(test_result['target'], test_result['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 0.8, 0.6, 0.2]\n",
      "[0]\ttrain-rmse:2.33435\teval-rmse:2.31993\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[508]\ttrain-rmse:0.080587\teval-rmse:0.17733\n",
      "\n",
      "[0]\ttrain-rmse:2.32603\teval-rmse:2.35314\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 50 rounds.\n",
      "[1000]\ttrain-rmse:0.036267\teval-rmse:0.190875\n",
      "Stopping. Best iteration:\n",
      "[964]\ttrain-rmse:0.038393\teval-rmse:0.19084\n",
      "\n",
      "[0]\ttrain-rmse:2.3309\teval-rmse:2.33339\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[626]\ttrain-rmse:0.067672\teval-rmse:0.14085\n",
      "\n",
      "[0]\ttrain-rmse:2.32928\teval-rmse:2.34094\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[702]\ttrain-rmse:0.058056\teval-rmse:0.166757\n",
      "\n",
      "[0]\ttrain-rmse:2.33676\teval-rmse:2.30969\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[543]\ttrain-rmse:0.075816\teval-rmse:0.187679\n",
      "\n",
      "Test MSE: 0.0301560999918\n",
      "[3, 0.8, 0.6, 0.4]\n",
      "[0]\ttrain-rmse:2.33296\teval-rmse:2.32607\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[584]\ttrain-rmse:0.070719\teval-rmse:0.147349\n",
      "\n",
      "[0]\ttrain-rmse:2.32895\teval-rmse:2.34105\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 50 rounds.\n"
     ]
    }
   ],
   "source": [
    "record = []\n",
    "for md in [3,4,5]:\n",
    "    for la in [0.8,1,1.3,1.5,2]:\n",
    "        for sp in [0.6,0.8,1]:\n",
    "            for cb in [0.2,0.4,0.6,0.8,1]:\n",
    "                tmp_record = [md,la,sp,cb]\n",
    "                print(tmp_record)\n",
    "                params = {'max_depth':md, 'eta':0.01, 'silent':0,'objective':'reg:linear','lambda':la,'subsample':sp,'colsample_bytree':cb}\n",
    "                tmp_record.append(xgb_kfold(dfTrain,dfPred,predictors,5,params=params)[3])\n",
    "                record.append(tmp_record)\n",
    "                GS_df = pd.DataFrame(record,columns=['max_depth','lambda','subsample','colsample_bytree','test_MSE'])\n",
    "                GS_df.to_csv('../../Profiling/GS_result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:2.33325\teval-rmse:2.32446\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 50 rounds.\n",
      "[50]\ttrain-rmse:1.42504\teval-rmse:1.41672\n",
      "[100]\ttrain-rmse:0.879138\teval-rmse:0.872982\n",
      "[150]\ttrain-rmse:0.55208\teval-rmse:0.555279\n",
      "[200]\ttrain-rmse:0.355857\teval-rmse:0.372674\n",
      "[250]\ttrain-rmse:0.236805\teval-rmse:0.272561\n",
      "[300]\ttrain-rmse:0.163235\teval-rmse:0.220306\n",
      "[350]\ttrain-rmse:0.117279\teval-rmse:0.19572\n",
      "[400]\ttrain-rmse:0.088505\teval-rmse:0.184687\n",
      "[450]\ttrain-rmse:0.069554\teval-rmse:0.180748\n",
      "[500]\ttrain-rmse:0.056817\teval-rmse:0.178809\n",
      "[550]\ttrain-rmse:0.047473\teval-rmse:0.17801\n",
      "[600]\ttrain-rmse:0.04041\teval-rmse:0.177439\n",
      "[650]\ttrain-rmse:0.034622\teval-rmse:0.17706\n",
      "[700]\ttrain-rmse:0.029927\teval-rmse:0.177028\n",
      "[750]\ttrain-rmse:0.025907\teval-rmse:0.176934\n",
      "[800]\ttrain-rmse:0.022595\teval-rmse:0.176859\n",
      "[850]\ttrain-rmse:0.019805\teval-rmse:0.176851\n",
      "Stopping. Best iteration:\n",
      "[819]\ttrain-rmse:0.021476\teval-rmse:0.17677\n",
      "\n",
      "[0]\ttrain-rmse:2.33442\teval-rmse:2.31983\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 50 rounds.\n",
      "[50]\ttrain-rmse:1.42637\teval-rmse:1.41143\n",
      "[100]\ttrain-rmse:0.880018\teval-rmse:0.867547\n",
      "[150]\ttrain-rmse:0.552915\teval-rmse:0.548479\n",
      "[200]\ttrain-rmse:0.356164\teval-rmse:0.365074\n",
      "[250]\ttrain-rmse:0.235907\teval-rmse:0.266178\n",
      "[300]\ttrain-rmse:0.161699\teval-rmse:0.217447\n",
      "[350]\ttrain-rmse:0.116264\teval-rmse:0.196616\n",
      "[400]\ttrain-rmse:0.08721\teval-rmse:0.187602\n",
      "[450]\ttrain-rmse:0.068744\teval-rmse:0.184633\n",
      "[500]\ttrain-rmse:0.056519\teval-rmse:0.183847\n",
      "[550]\ttrain-rmse:0.047605\teval-rmse:0.183498\n",
      "[600]\ttrain-rmse:0.040708\teval-rmse:0.183611\n",
      "Stopping. Best iteration:\n",
      "[550]\ttrain-rmse:0.047605\teval-rmse:0.183498\n",
      "\n",
      "[0]\ttrain-rmse:2.32128\teval-rmse:2.37266\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 50 rounds.\n",
      "[50]\ttrain-rmse:1.41768\teval-rmse:1.46923\n",
      "[100]\ttrain-rmse:0.874397\teval-rmse:0.926371\n",
      "[150]\ttrain-rmse:0.550305\teval-rmse:0.60405\n",
      "[200]\ttrain-rmse:0.355075\teval-rmse:0.414502\n",
      "[250]\ttrain-rmse:0.235515\teval-rmse:0.307053\n",
      "[300]\ttrain-rmse:0.162647\teval-rmse:0.248968\n",
      "[350]\ttrain-rmse:0.116702\teval-rmse:0.219699\n",
      "[400]\ttrain-rmse:0.088322\teval-rmse:0.204807\n",
      "[450]\ttrain-rmse:0.069256\teval-rmse:0.197488\n",
      "[500]\ttrain-rmse:0.056755\teval-rmse:0.193662\n",
      "[550]\ttrain-rmse:0.04805\teval-rmse:0.191852\n",
      "[600]\ttrain-rmse:0.041349\teval-rmse:0.190863\n",
      "[650]\ttrain-rmse:0.035509\teval-rmse:0.190005\n",
      "[700]\ttrain-rmse:0.0308\teval-rmse:0.189742\n",
      "[750]\ttrain-rmse:0.02668\teval-rmse:0.189272\n",
      "[800]\ttrain-rmse:0.023137\teval-rmse:0.189192\n",
      "[850]\ttrain-rmse:0.020157\teval-rmse:0.18901\n",
      "Stopping. Best iteration:\n",
      "[831]\ttrain-rmse:0.021132\teval-rmse:0.188983\n",
      "\n",
      "[0]\ttrain-rmse:2.33315\teval-rmse:2.3247\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 50 rounds.\n",
      "[50]\ttrain-rmse:1.42498\teval-rmse:1.41655\n",
      "[100]\ttrain-rmse:0.879532\teval-rmse:0.873154\n",
      "[150]\ttrain-rmse:0.55311\teval-rmse:0.554023\n",
      "[200]\ttrain-rmse:0.356215\teval-rmse:0.370517\n",
      "[250]\ttrain-rmse:0.236455\teval-rmse:0.269497\n",
      "[300]\ttrain-rmse:0.162869\teval-rmse:0.217386\n",
      "[350]\ttrain-rmse:0.116988\teval-rmse:0.192301\n",
      "[400]\ttrain-rmse:0.087698\teval-rmse:0.180854\n",
      "[450]\ttrain-rmse:0.069074\teval-rmse:0.175795\n",
      "[500]\ttrain-rmse:0.056505\teval-rmse:0.173312\n",
      "[550]\ttrain-rmse:0.047347\teval-rmse:0.172125\n",
      "[600]\ttrain-rmse:0.040307\teval-rmse:0.171255\n",
      "[650]\ttrain-rmse:0.034436\teval-rmse:0.17082\n",
      "[700]\ttrain-rmse:0.029959\teval-rmse:0.170616\n",
      "[750]\ttrain-rmse:0.026083\teval-rmse:0.170547\n",
      "[800]\ttrain-rmse:0.022712\teval-rmse:0.170376\n",
      "[850]\ttrain-rmse:0.019694\teval-rmse:0.170312\n",
      "Stopping. Best iteration:\n",
      "[819]\ttrain-rmse:0.021477\teval-rmse:0.170252\n",
      "\n",
      "[0]\ttrain-rmse:2.33556\teval-rmse:2.31557\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 50 rounds.\n",
      "[50]\ttrain-rmse:1.42643\teval-rmse:1.40585\n",
      "[100]\ttrain-rmse:0.880586\teval-rmse:0.86033\n",
      "[150]\ttrain-rmse:0.553593\teval-rmse:0.542548\n",
      "[200]\ttrain-rmse:0.35683\teval-rmse:0.357494\n",
      "[250]\ttrain-rmse:0.237037\teval-rmse:0.254259\n",
      "[300]\ttrain-rmse:0.163012\teval-rmse:0.200446\n",
      "[350]\ttrain-rmse:0.117768\teval-rmse:0.173518\n",
      "[400]\ttrain-rmse:0.089302\teval-rmse:0.16171\n",
      "[450]\ttrain-rmse:0.070598\teval-rmse:0.15657\n",
      "[500]\ttrain-rmse:0.058014\teval-rmse:0.153563\n",
      "[550]\ttrain-rmse:0.048865\teval-rmse:0.1525\n",
      "[600]\ttrain-rmse:0.041959\teval-rmse:0.151907\n",
      "[650]\ttrain-rmse:0.03635\teval-rmse:0.151331\n",
      "[700]\ttrain-rmse:0.031464\teval-rmse:0.151055\n",
      "[750]\ttrain-rmse:0.027272\teval-rmse:0.150873\n",
      "[800]\ttrain-rmse:0.023755\teval-rmse:0.150768\n",
      "[850]\ttrain-rmse:0.020823\teval-rmse:0.150581\n",
      "[900]\ttrain-rmse:0.018146\teval-rmse:0.150402\n",
      "[950]\ttrain-rmse:0.015977\teval-rmse:0.150459\n",
      "Stopping. Best iteration:\n",
      "[901]\ttrain-rmse:0.018095\teval-rmse:0.1504\n",
      "\n",
      "Test MSE: 0.0304553713821\n"
     ]
    }
   ],
   "source": [
    "test_result,result,imp = xgb_kfold(dfTrain,dfPred,predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp.to_csv('../../Profiling/imp_test_v3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result['score']=result[['Score_1','Score_2','Score_3','Score_4','Score_5']].mean(axis=1)\n",
    "submit = result[['ID','score']]\n",
    "today = datetime.date.today().strftime('%Y-%m-%d')\n",
    "submit.to_csv('../../Submission/submit_%s.csv'%today,header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#貌似RF根本就不需要CV啊，其实也行吧\n",
    "def rf_kfold(dfTrain,dfPred,predictors,n_splits=5):  \n",
    "    kf = KFold(n_splits=n_splits,shuffle=True)\n",
    "    dpred = xgb.DMatrix(dfPred[predictors].values,label=[0]*len(dfPred),missing=np.nan)\n",
    "    imp = pd.DataFrame({'variable':predictors,'lk':['f'+str(i) for i in range(len(predictors))]})\n",
    "    round=0\n",
    "    for train_index, test_index in kf.split(dfTrain):\n",
    "        round+=1\n",
    "        train_X = dfTrain.loc[train_index,predictors].values\n",
    "        test_X = dfTrain.loc[test_index,predictors].values\n",
    "        train_Y = dfTrain.loc[train_index,'Y'].values\n",
    "        test_Y = dfTrain.loc[test_index,'Y'].values\n",
    " \n",
    "        model = RandomForestRegressor(n_estimators=1999, max_features='sqrt', max_depth=None, max_depth=4, compute_importances=True, random_state=615)  \n",
    "        model.fit(train_X,train_Y)\n",
    "        pred_test = model.predict(test_X）\n",
    "        pred_score = model.predict(dfPred[predictors].values)\n",
    "        if round==1:\n",
    "            test_result = pd.DataFrame({'ID':dfTrain.loc[test_index,'ID'].values,'score':pred_test,'target':test_Y})\n",
    "            result = pd.DataFrame({'ID':dfPred['ID'],'Score_%d'%round:pred_score})\n",
    "        else:\n",
    "            test_result = pd.concat([test_result,pd.DataFrame({'ID':dfTrain.loc[test_index,'ID'].values,'score':pred_test,'target':test_Y})],axis=0)\n",
    "            result = result.merge(pd.DataFrame({'ID':dfPred['ID'],'Score_%d'%round:pred_score}),'inner','ID')\n",
    "    print(\"Test MSE:\",metrics.mean_squared_error(test_result['target'], test_result['score']))\n",
    "    return test_result,result,imp,metrics.mean_squared_error(test_result['target'], test_result['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RF填缺失值"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
