{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data...\n",
      "Done.\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from nlp_utils import clean_text, pos_tag_text\n",
    "sys.path.append(\"../\")\n",
    "from param_config import config\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "import datetime\n",
    "from sklearn.linear_model import LassoLars\n",
    " \n",
    "\n",
    "pd.set_option('display.float_format',lambda x: '%.5f'%x)\n",
    "\n",
    "print(\"Load data...\")\n",
    "\n",
    "dfTrain = pd.read_csv(config.original_train_data_path)\n",
    "\n",
    "dfPred= pd.read_csv(config.original_test_data_path)\n",
    "#dfPred2= pd.read_csv(config.original_test_data2_path)\n",
    "# number of train/test samples\n",
    "num_train, num_pred = dfTrain.shape[0], dfPred.shape[0]\n",
    "\n",
    "print(\"Done.\")\n",
    "\n",
    "f = open('../../Data/col_name.txt','r')  \n",
    "a = f.read()  \n",
    "col_name = eval(a)  \n",
    "f.close() \n",
    "\n",
    "f = open('../../Data/Procedure.txt','r')  \n",
    "a = f.read()  \n",
    "procedure = eval(a)  \n",
    "f.close()\n",
    "\n",
    "f = open('../../Cache/var_change.txt','r')\n",
    "a = f.read()\n",
    "var_change = eval(a)\n",
    "f.close()\n",
    "\n",
    "dfTrain = dfTrain.rename(columns=col_name)\n",
    "raw_predictors = dfTrain.columns.tolist()[1:-1]\n",
    "dfTrain = dfTrain.set_index(dfTrain['ID'])\n",
    "dfPred = dfPred.rename(columns=col_name)\n",
    "dfPred = dfPred.set_index(dfPred['ID'])\n",
    "print('Y' in raw_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Feat_file = ['Feat_cnt_col_non_missing','Feat_cnt_tool_non_missing','Feat_pcent_col_non_missing','Feat_pcent_tool_non_missing','Feat_minus_non_missing']\n",
    "ex_feat = []\n",
    "for filename in Feat_file:\n",
    "    if filename == 'Feat_minus_non_missing':\n",
    "        tmp = pd.read_csv('../../../'+filename+'.csv')\n",
    "    else:\n",
    "        tmp = pd.read_csv('../../Cache/'+filename+'.csv')\n",
    "    tmp.set_index(tmp['ID'],inplace=True,drop=True)\n",
    "    tmp_feat_list = tmp.columns.tolist()\n",
    "    if 'ID' in tmp_feat_list:\n",
    "        tmp_feat_list.remove('ID')\n",
    "    ex_feat += tmp_feat_list\n",
    "    dfTrain = pd.merge(dfTrain,tmp,'left','ID')\n",
    "    dfPred = pd.merge(dfPred,tmp,'left','ID')\n",
    "    \n",
    "predictors = raw_predictors+ex_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOOL_310_E\n",
      "TOOL_340_2409.0\n",
      "TOOL_344_T\n",
      "TOOL_360_C\n"
     ]
    }
   ],
   "source": [
    "#define the input variables, dummies\n",
    "predictors = raw_predictors+ex_feat\n",
    "feat_cnt = 0\n",
    "for key,value in var_change.items():\n",
    "    feat_cnt+=1\n",
    "    if feat_cnt>1:\n",
    "        continue\n",
    "    for var in var_change[key]['constant']:\n",
    "        try:\n",
    "            predictors.remove(var)\n",
    "        except:\n",
    "            continue\n",
    "    for var in var_change[key]['category']:\n",
    "        if not 'TOOL' in var:\n",
    "            continue\n",
    "        try:\n",
    "            predictors.remove(var)\n",
    "        except:\n",
    "            continue\n",
    "        tmpTrain = pd.get_dummies(dfTrain[var],prefix=var,dummy_na=True)\n",
    "        tmpPred = pd.get_dummies(dfPred[var],prefix=var,dummy_na=True)\n",
    "        predictors = predictors + tmpTrain.columns.tolist()\n",
    "        dfTrain = pd.concat([dfTrain,tmpTrain],axis=1)\n",
    "        dfPred = pd.concat([dfPred,tmpPred],axis=1)\n",
    "for var in predictors:\n",
    "    if var not in dfPred.columns:\n",
    "        print(var)\n",
    "        dfPred[var] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 30458)\n",
      "(100, 30458)\n",
      "30458\n"
     ]
    }
   ],
   "source": [
    "print(dfTrain[predictors].shape)\n",
    "print(dfPred[predictors].shape)\n",
    "print(len(predictors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ...,  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "##feature selection by lasso/lars\n",
    "reg = LassoLars(alpha=0.01,copy_X=True, eps=..., fit_intercept=True,\n",
    "     fit_path=True, max_iter=5000, normalize=True, positive=False,\n",
    "     precompute='auto', verbose=False)\n",
    "reg.fit( dfTrain[predictors], dfTrain['Y'])\n",
    "print(reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "##feature selection by RF\n",
    "from sklearn.ensemble import RandomForestRegressor  \n",
    "import numpy as np  \n",
    "\n",
    "'''rf = RandomForestRegressor(n_estimators=5000, max_features='sqrt',  max_depth=4, random_state=615)  \n",
    "rf.fit(dfTrain[predictors], dfTrain['Y'])  \n",
    "\n",
    "rf_imp_df = pd.DataFrame({'var':predictors,'imp':rf.feature_importances_})\n",
    "rf_imp_df.sort_values('imp',ascending=False,inplace =True)\n",
    "'''\n",
    "feat_num = 2000\n",
    "creteria = rf_imp_df.iloc[feat_num-1,0]\n",
    "predictors_rf = rf_imp_df.loc[rf_imp_df['imp']>=creteria,'var'].values.tolist()\n",
    "print(len(predictors_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "##feature selection by pearson correlation\n",
    "'''corr = dfTrain[predictors+['Y']].corr()\n",
    "corr_y = corr.loc[corr['Y']!=1&corr['Y'].notnull(),'Y']'''\n",
    "for i in range(20000):\n",
    "    criteria = 0.3 - 0.0001*i\n",
    "    length = (corr_y<-criteria).sum()+(corr_y>criteria).sum()\n",
    "    if length>=200:\n",
    "        ind = corr.loc[(corr['Y']<-criteria)|(corr['Y']>criteria),'Y']\n",
    "        break\n",
    "ind = np.abs(ind)\n",
    "ind = ind.sort_values(ascending=False)\n",
    "#predictors_pear = ind.iloc[0:len(predictors_rf)+1].index.tolist()\n",
    "predictors_pear = ind.index.tolist()\n",
    "predictors_pear.remove('Y')\n",
    "selected_feat = predictors_pear.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(len(predictors_pear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_feat_df = pd.DataFrame({'RandomForest':predictors_rf,'PearsonCorr':predictors_pear})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "selected_feat = []\n",
    "i=0\n",
    "while len(selected_feat)<2000:\n",
    "    if selected_feat_df.loc[i,'RandomForest'] not in selected_feat:\n",
    "        selected_feat.append(selected_feat_df.loc[i,'RandomForest'])\n",
    "    if selected_feat_df.loc[i,'PearsonCorr'] not in selected_feat:\n",
    "        selected_feat.append(selected_feat_df.loc[i,'PearsonCorr'])\n",
    "    i+=1\n",
    "print(i)\n",
    "print(len(selected_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_kfold(dfTrain,dfPred,predictors,n_splits=5,weight = 1,early_stop = 10,ins_rmse = 0,params = {'max_depth':3, 'eta':0.01, 'silent':0,'objective':'reg:linear','lambda':1,'subsample':0.8,\n",
    "                         'colsample_bytree':0.8}):  \n",
    "    kf = KFold(n_splits=n_splits,shuffle=True)\n",
    "    dpred = xgb.DMatrix(dfPred[predictors].values,label=[0]*len(dfPred),missing=np.nan)\n",
    "    imp = pd.DataFrame({'variable':predictors,'lk':['f'+str(i) for i in range(len(predictors))]})\n",
    "    round=0\n",
    "    if weight>1:\n",
    "        tmp = np.abs(dfTrain['Y'] - dfTrain['Y'].quantile(0.5))\n",
    "        dfTrain['wgt'] = 1+(weight-1)*(np.abs(dfTrain['Y'] - dfTrain['Y'].quantile(0.5))/np.abs(dfTrain['Y'] - dfTrain['Y'].quantile(0.5)).max())\n",
    "    else:\n",
    "        dfTrain['wgt'] = 1\n",
    "    for train_index, test_index in kf.split(dfTrain):\n",
    "        round+=1\n",
    "        train_X = dfTrain.loc[train_index,predictors]\n",
    "        test_X = dfTrain.loc[test_index,predictors]\n",
    "        train_Y = dfTrain.loc[train_index,'Y']\n",
    "        test_Y = dfTrain.loc[test_index,'Y']\n",
    "        train_wgt = dfTrain.loc[train_index,'wgt']\n",
    "        test_wgt = dfTrain.loc[test_index,'wgt']\n",
    "\n",
    "        dtrain = xgb.DMatrix(train_X.values, label=train_Y.values,weight=train_wgt, missing = np.nan)\n",
    "        dtest = xgb.DMatrix(test_X.values, label=test_Y.values,weight=test_wgt, missing = np.nan)\n",
    "        param = params \n",
    "        evallist  = [(dtrain,'train'),(dtest,'eval')]  \n",
    "        num_round = 5000\n",
    "        evals_dict = {}\n",
    "        model = xgb.train(param,dtrain,num_round, evallist,early_stopping_rounds=early_stop,evals_result=evals_dict,verbose_eval =100)\n",
    "        performance_df = pd.DataFrame({'train':evals_dict['train']['rmse'],'eval':evals_dict['eval']['rmse']})\n",
    "        performance_df =performance_df.loc[performance_df['train']>=ins_rmse]\n",
    "        #bst_tree = len(performance_df)-1-early_stop\n",
    "        bst_tree = performance_df.loc[performance_df['eval']==performance_df['eval'].min()].index.tolist()[0] + 1\n",
    "        print('Best tree is %d, performance is %f, %f'%(bst_tree,performance_df.loc[bst_tree-1,'train'],performance_df.loc[bst_tree-1,'eval']))\n",
    "        pred_test = model.predict(dtest,ntree_limit =bst_tree)\n",
    "\n",
    "        tmp_imp = pd.DataFrame(model.get_score(importance_type='gain'),index=['imp_fold%d'%round]).T\n",
    "        tmp_imp['lk'] = tmp_imp.index\n",
    "        imp = imp.merge(tmp_imp,'left','lk').fillna(0)\n",
    "\n",
    "\n",
    "        pred_score = model.predict(dpred,ntree_limit =bst_tree)\n",
    "        if round==1:\n",
    "            test_result = pd.DataFrame({'ID':dfTrain.loc[test_index,'ID'].values,'score':pred_test,'target':test_Y})\n",
    "            result = pd.DataFrame({'ID':dfPred['ID'],'Score_%d'%round:pred_score})\n",
    "        else:\n",
    "            test_result = pd.concat([test_result,pd.DataFrame({'ID':dfTrain.loc[test_index,'ID'].values,'score':pred_test,'target':test_Y})],axis=0)\n",
    "            result = result.merge(pd.DataFrame({'ID':dfPred['ID'],'Score_%d'%round:pred_score}),'inner','ID')\n",
    "    print(\"Test MSE:\",metrics.mean_squared_error(test_result['target'], test_result['score']))\n",
    "    return test_result,result,imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:2.33206\teval-rmse:2.3267\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 10 rounds.\n",
      "[100]\ttrain-rmse:0.875143\teval-rmse:0.870066\n",
      "[200]\ttrain-rmse:0.353898\teval-rmse:0.360667\n",
      "[300]\ttrain-rmse:0.178192\teval-rmse:0.203826\n",
      "[400]\ttrain-rmse:0.12664\teval-rmse:0.17042\n",
      "[500]\ttrain-rmse:0.109074\teval-rmse:0.165181\n",
      "Stopping. Best iteration:\n",
      "[506]\ttrain-rmse:0.108313\teval-rmse:0.164867\n",
      "\n",
      "Best tree is 507, performance is 0.108313, 0.164867\n",
      "[0]\ttrain-rmse:2.33163\teval-rmse:2.32916\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 10 rounds.\n",
      "[100]\ttrain-rmse:0.874198\teval-rmse:0.874967\n",
      "[200]\ttrain-rmse:0.353796\teval-rmse:0.356122\n",
      "[300]\ttrain-rmse:0.179046\teval-rmse:0.19007\n",
      "[400]\ttrain-rmse:0.128136\teval-rmse:0.151756\n",
      "[500]\ttrain-rmse:0.110483\teval-rmse:0.14396\n",
      "[600]\ttrain-rmse:0.101084\teval-rmse:0.141674\n",
      "Stopping. Best iteration:\n",
      "[646]\ttrain-rmse:0.097241\teval-rmse:0.140787\n",
      "\n",
      "Best tree is 610, performance is 0.100416, 0.141453\n",
      "[0]\ttrain-rmse:2.33077\teval-rmse:2.33777\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 10 rounds.\n",
      "[100]\ttrain-rmse:0.874714\teval-rmse:0.880712\n",
      "[200]\ttrain-rmse:0.35356\teval-rmse:0.3726\n",
      "[300]\ttrain-rmse:0.177547\teval-rmse:0.214712\n",
      "[400]\ttrain-rmse:0.125931\teval-rmse:0.17943\n",
      "[500]\ttrain-rmse:0.108849\teval-rmse:0.173276\n",
      "Stopping. Best iteration:\n",
      "[506]\ttrain-rmse:0.10807\teval-rmse:0.173078\n",
      "\n",
      "Best tree is 507, performance is 0.108070, 0.173078\n",
      "[0]\ttrain-rmse:2.33346\teval-rmse:2.3122\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 10 rounds.\n",
      "[100]\ttrain-rmse:0.875412\teval-rmse:0.856616\n",
      "[200]\ttrain-rmse:0.353557\teval-rmse:0.35392\n",
      "[300]\ttrain-rmse:0.178293\teval-rmse:0.202549\n",
      "[400]\ttrain-rmse:0.126357\teval-rmse:0.169323\n",
      "[500]\ttrain-rmse:0.108918\teval-rmse:0.163437\n",
      "Stopping. Best iteration:\n",
      "[540]\ttrain-rmse:0.104777\teval-rmse:0.162459\n",
      "\n",
      "Best tree is 541, performance is 0.104777, 0.162459\n",
      "[0]\ttrain-rmse:2.33471\teval-rmse:2.30125\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 10 rounds.\n",
      "[100]\ttrain-rmse:0.875652\teval-rmse:0.845437\n",
      "[200]\ttrain-rmse:0.352598\teval-rmse:0.344473\n",
      "[300]\ttrain-rmse:0.176337\teval-rmse:0.203026\n",
      "[400]\ttrain-rmse:0.125012\teval-rmse:0.177288\n",
      "Stopping. Best iteration:\n",
      "[465]\ttrain-rmse:0.112168\teval-rmse:0.174228\n",
      "\n",
      "Best tree is 466, performance is 0.112168, 0.174228\n",
      "[0]\ttrain-rmse:2.33114\teval-rmse:2.3344\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 10 rounds.\n",
      "[100]\ttrain-rmse:0.874248\teval-rmse:0.878727\n",
      "[200]\ttrain-rmse:0.353188\teval-rmse:0.368613\n",
      "[300]\ttrain-rmse:0.178\teval-rmse:0.205858\n",
      "[400]\ttrain-rmse:0.126993\teval-rmse:0.167644\n",
      "[500]\ttrain-rmse:0.109214\teval-rmse:0.159478\n",
      "Stopping. Best iteration:\n",
      "[538]\ttrain-rmse:0.105161\teval-rmse:0.158213\n",
      "\n",
      "Best tree is 539, performance is 0.105161, 0.158213\n",
      "[0]\ttrain-rmse:2.32958\teval-rmse:2.34835\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 10 rounds.\n",
      "[100]\ttrain-rmse:0.87378\teval-rmse:0.890125\n",
      "[200]\ttrain-rmse:0.352704\teval-rmse:0.370273\n",
      "[300]\ttrain-rmse:0.177306\teval-rmse:0.211977\n",
      "[400]\ttrain-rmse:0.126006\teval-rmse:0.179993\n",
      "[500]\ttrain-rmse:0.108838\teval-rmse:0.175599\n",
      "Stopping. Best iteration:\n",
      "[505]\ttrain-rmse:0.108304\teval-rmse:0.17544\n",
      "\n",
      "Best tree is 506, performance is 0.108304, 0.175440\n",
      "[0]\ttrain-rmse:2.32716\teval-rmse:2.37034\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 10 rounds.\n",
      "[100]\ttrain-rmse:0.873182\teval-rmse:0.919766\n",
      "[200]\ttrain-rmse:0.352011\teval-rmse:0.403332\n",
      "[300]\ttrain-rmse:0.176981\teval-rmse:0.235221\n",
      "[400]\ttrain-rmse:0.125482\teval-rmse:0.190289\n",
      "[500]\ttrain-rmse:0.107688\teval-rmse:0.178535\n",
      "Stopping. Best iteration:\n",
      "[544]\ttrain-rmse:0.10303\teval-rmse:0.176742\n",
      "\n",
      "Best tree is 545, performance is 0.103030, 0.176742\n",
      "[0]\ttrain-rmse:2.33323\teval-rmse:2.31399\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 10 rounds.\n",
      "[100]\ttrain-rmse:0.87511\teval-rmse:0.860783\n",
      "[200]\ttrain-rmse:0.35273\teval-rmse:0.355951\n",
      "[300]\ttrain-rmse:0.17637\teval-rmse:0.209554\n",
      "[400]\ttrain-rmse:0.12432\teval-rmse:0.184291\n",
      "Stopping. Best iteration:\n",
      "[464]\ttrain-rmse:0.11147\teval-rmse:0.18203\n",
      "\n",
      "Best tree is 465, performance is 0.111470, 0.182030\n",
      "[0]\ttrain-rmse:2.33063\teval-rmse:2.33948\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 10 rounds.\n",
      "[100]\ttrain-rmse:0.873612\teval-rmse:0.883196\n",
      "[200]\ttrain-rmse:0.352702\teval-rmse:0.368507\n",
      "[300]\ttrain-rmse:0.177548\teval-rmse:0.211694\n",
      "[400]\ttrain-rmse:0.126477\teval-rmse:0.178766\n",
      "Stopping. Best iteration:\n",
      "[438]\ttrain-rmse:0.118065\teval-rmse:0.175777\n",
      "\n",
      "Best tree is 439, performance is 0.118065, 0.175777\n",
      "Test MSE: 0.0284975057619\n"
     ]
    }
   ],
   "source": [
    "n_splits = 10\n",
    "early_stop =10\n",
    "ins_rmse = 0.1\n",
    "test_result,result,imp = xgb_kfold(dfTrain,dfPred,selected_feat,n_splits=n_splits,early_stop=early_stop,ins_rmse = ins_rmse)\n",
    "\n",
    "#test = xgb_kfold(dfTrain,dfPred,selected_feat,n_splits=n_splits,early_stop=early_stop,ins_rmse = ins_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "other_note ='300feat'\n",
    "result['score']=result[['Score_%d'%i for i in range(1,n_splits+1)]].mean(axis=1)\n",
    "submit = result[['ID','score']]\n",
    "today = datetime.date.today().strftime('%Y-%m-%d')\n",
    "result.to_csv('../../Submission/result/result_%s'%today+other_note+'.csv',index=False)\n",
    "submit.to_csv('../../Submission/submit_%s'%today+other_note+'.csv',header=False,index=False)\n",
    "test_result.to_csv('../../Submission/test/test_result_%s'%today+other_note+'.csv',index=False)\n",
    "imp.to_csv('../../Submission/imp/importance_%s'%today+other_note+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RF & Pearson\n",
    "1000  0.0264600389016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RF\n",
    "500   0.0261706354963\n",
    "800   0.0261447242005\n",
    "1000  0.025398174979 / 0.026301476152\n",
    "2000  0.0259095708883"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pearson \n",
    "5000   0.0275283319973\n",
    "3000   0.0276070372856\n",
    "2000   0.0273172188618\n",
    "1000   0.0275733258446\n",
    "500    0.0272536288561\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pearson bound train\n",
    "1000   0.0281311064524\n",
    "300    0.0266287952817  0.1为界\n",
    "200    0.0276849909632  0.1为界\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
